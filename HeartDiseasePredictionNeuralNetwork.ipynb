{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeartDiseasePredictionNeuralNetwork.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOm7rFUGufBCX2Vk4+Q86hh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Advaitkale/Heart-Disease-Prediction/blob/master/HeartDiseasePredictionNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGxBImb3_w9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipKjLA_3APkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "62fbb0b3-d9ef-4708-ccf0-419cf170295c"
      },
      "source": [
        "data=pd.read_csv(\"framingham.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>currentSmoker</th>\n",
              "      <th>cigsPerDay</th>\n",
              "      <th>BPMeds</th>\n",
              "      <th>prevalentStroke</th>\n",
              "      <th>prevalentHyp</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>totChol</th>\n",
              "      <th>sysBP</th>\n",
              "      <th>diaBP</th>\n",
              "      <th>BMI</th>\n",
              "      <th>heartRate</th>\n",
              "      <th>glucose</th>\n",
              "      <th>TenYearCHD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>26.97</td>\n",
              "      <td>80.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>28.73</td>\n",
              "      <td>95.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>127.5</td>\n",
              "      <td>80.0</td>\n",
              "      <td>25.34</td>\n",
              "      <td>75.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>28.58</td>\n",
              "      <td>65.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>285.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>23.10</td>\n",
              "      <td>85.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   male  age  education  currentSmoker  ...    BMI  heartRate  glucose  TenYearCHD\n",
              "0     1   39        4.0              0  ...  26.97       80.0     77.0           0\n",
              "1     0   46        2.0              0  ...  28.73       95.0     76.0           0\n",
              "2     1   48        1.0              1  ...  25.34       75.0     70.0           0\n",
              "3     0   61        3.0              1  ...  28.58       65.0    103.0           1\n",
              "4     0   46        3.0              1  ...  23.10       85.0     85.0           0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJwkQ2fmjpSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cde0515f-636e-4951-bbfa-503260c17409"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4238, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FXG67rxAYRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data.dropna()\n",
        "X = data[['male','age','education','currentSmoker','cigsPerDay','BPMeds','prevalentStroke','prevalentHyp','diabetes',\n",
        "      'totChol','sysBP','diaBP','BMI','heartRate','glucose']]\n",
        "Y = to_categorical(data['TenYearCHD'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZEg9zfuGJbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "913e5c3a-b888-4171-837f-e3fa0c0725bc"
      },
      "source": [
        "Y\n",
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3656, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUJsVktSA0Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG6qtCpUEVOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(38, input_dim=X.shape[1], activation='relu',activity_regularizer=regularizers.l2(1e-4)))\n",
        "model.add(Dense(38, activation='sigmoid',activity_regularizer=regularizers.l2(1e-4)))\n",
        "model.add(Dense(38, activation='relu',activity_regularizer=regularizers.l2(1e-4)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(Y.shape[1], activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl9zwLXMEoIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35059e24-d752-4221-f205-16d0949383c8"
      },
      "source": [
        "history=model.fit(X_train,Y_train,validation_data=(X_test, Y_test), epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.7727 - accuracy: 0.7295 - val_loss: 1.3330 - val_accuracy: 0.8634\n",
            "Epoch 2/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.8124 - accuracy: 0.8437 - val_loss: 0.5146 - val_accuracy: 0.8634\n",
            "Epoch 3/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8437 - val_loss: 0.4206 - val_accuracy: 0.8634\n",
            "Epoch 4/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8440 - val_loss: 0.4042 - val_accuracy: 0.8634\n",
            "Epoch 5/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8437 - val_loss: 0.3992 - val_accuracy: 0.8634\n",
            "Epoch 6/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8434 - val_loss: 0.4035 - val_accuracy: 0.8620\n",
            "Epoch 7/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8451 - val_loss: 0.3934 - val_accuracy: 0.8620\n",
            "Epoch 8/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8451 - val_loss: 0.4224 - val_accuracy: 0.8593\n",
            "Epoch 9/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8471 - val_loss: 0.4002 - val_accuracy: 0.8634\n",
            "Epoch 10/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8482 - val_loss: 0.3970 - val_accuracy: 0.8648\n",
            "Epoch 11/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8468 - val_loss: 0.3918 - val_accuracy: 0.8634\n",
            "Epoch 12/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8478 - val_loss: 0.3898 - val_accuracy: 0.8648\n",
            "Epoch 13/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8468 - val_loss: 0.4013 - val_accuracy: 0.8634\n",
            "Epoch 14/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8471 - val_loss: 0.3950 - val_accuracy: 0.8648\n",
            "Epoch 15/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8478 - val_loss: 0.3928 - val_accuracy: 0.8607\n",
            "Epoch 16/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8495 - val_loss: 0.3917 - val_accuracy: 0.8634\n",
            "Epoch 17/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8492 - val_loss: 0.3972 - val_accuracy: 0.8579\n",
            "Epoch 18/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8478 - val_loss: 0.3948 - val_accuracy: 0.8634\n",
            "Epoch 19/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8495 - val_loss: 0.3998 - val_accuracy: 0.8579\n",
            "Epoch 20/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8488 - val_loss: 0.3962 - val_accuracy: 0.8634\n",
            "Epoch 21/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8502 - val_loss: 0.4040 - val_accuracy: 0.8552\n",
            "Epoch 22/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8488 - val_loss: 0.4005 - val_accuracy: 0.8579\n",
            "Epoch 23/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8495 - val_loss: 0.3978 - val_accuracy: 0.8579\n",
            "Epoch 24/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8505 - val_loss: 0.3940 - val_accuracy: 0.8607\n",
            "Epoch 25/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8495 - val_loss: 0.3974 - val_accuracy: 0.8566\n",
            "Epoch 26/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8488 - val_loss: 0.3963 - val_accuracy: 0.8579\n",
            "Epoch 27/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8502 - val_loss: 0.3934 - val_accuracy: 0.8648\n",
            "Epoch 28/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8492 - val_loss: 0.3988 - val_accuracy: 0.8593\n",
            "Epoch 29/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8499 - val_loss: 0.4041 - val_accuracy: 0.8511\n",
            "Epoch 30/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8512 - val_loss: 0.3906 - val_accuracy: 0.8634\n",
            "Epoch 31/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8492 - val_loss: 0.3942 - val_accuracy: 0.8579\n",
            "Epoch 32/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8492 - val_loss: 0.3986 - val_accuracy: 0.8566\n",
            "Epoch 33/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8502 - val_loss: 0.4164 - val_accuracy: 0.8484\n",
            "Epoch 34/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8495 - val_loss: 0.3960 - val_accuracy: 0.8620\n",
            "Epoch 35/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8502 - val_loss: 0.3912 - val_accuracy: 0.8634\n",
            "Epoch 36/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8492 - val_loss: 0.3943 - val_accuracy: 0.8620\n",
            "Epoch 37/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8505 - val_loss: 0.3948 - val_accuracy: 0.8620\n",
            "Epoch 38/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8519 - val_loss: 0.4072 - val_accuracy: 0.8552\n",
            "Epoch 39/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8509 - val_loss: 0.3964 - val_accuracy: 0.8607\n",
            "Epoch 40/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8505 - val_loss: 0.3970 - val_accuracy: 0.8620\n",
            "Epoch 41/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8495 - val_loss: 0.4011 - val_accuracy: 0.8648\n",
            "Epoch 42/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8529 - val_loss: 0.3973 - val_accuracy: 0.8579\n",
            "Epoch 43/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8492 - val_loss: 0.3905 - val_accuracy: 0.8634\n",
            "Epoch 44/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8502 - val_loss: 0.3926 - val_accuracy: 0.8620\n",
            "Epoch 45/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8509 - val_loss: 0.3983 - val_accuracy: 0.8607\n",
            "Epoch 46/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8516 - val_loss: 0.3968 - val_accuracy: 0.8593\n",
            "Epoch 47/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8495 - val_loss: 0.4054 - val_accuracy: 0.8593\n",
            "Epoch 48/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8526 - val_loss: 0.4083 - val_accuracy: 0.8511\n",
            "Epoch 49/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8519 - val_loss: 0.3951 - val_accuracy: 0.8607\n",
            "Epoch 50/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8505 - val_loss: 0.3985 - val_accuracy: 0.8566\n",
            "Epoch 51/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8519 - val_loss: 0.4098 - val_accuracy: 0.8566\n",
            "Epoch 52/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8519 - val_loss: 0.3961 - val_accuracy: 0.8607\n",
            "Epoch 53/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8536 - val_loss: 0.3908 - val_accuracy: 0.8634\n",
            "Epoch 54/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8519 - val_loss: 0.3931 - val_accuracy: 0.8607\n",
            "Epoch 55/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8519 - val_loss: 0.4072 - val_accuracy: 0.8538\n",
            "Epoch 56/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8516 - val_loss: 0.3949 - val_accuracy: 0.8634\n",
            "Epoch 57/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8523 - val_loss: 0.3984 - val_accuracy: 0.8620\n",
            "Epoch 58/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8543 - val_loss: 0.3952 - val_accuracy: 0.8593\n",
            "Epoch 59/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8523 - val_loss: 0.3979 - val_accuracy: 0.8634\n",
            "Epoch 60/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8519 - val_loss: 0.3940 - val_accuracy: 0.8634\n",
            "Epoch 61/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8547 - val_loss: 0.3977 - val_accuracy: 0.8593\n",
            "Epoch 62/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8533 - val_loss: 0.4031 - val_accuracy: 0.8497\n",
            "Epoch 63/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8543 - val_loss: 0.3969 - val_accuracy: 0.8593\n",
            "Epoch 64/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8492 - val_loss: 0.3967 - val_accuracy: 0.8607\n",
            "Epoch 65/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8543 - val_loss: 0.4034 - val_accuracy: 0.8538\n",
            "Epoch 66/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8512 - val_loss: 0.4001 - val_accuracy: 0.8634\n",
            "Epoch 67/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8533 - val_loss: 0.4070 - val_accuracy: 0.8497\n",
            "Epoch 68/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8529 - val_loss: 0.4029 - val_accuracy: 0.8593\n",
            "Epoch 69/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8526 - val_loss: 0.4037 - val_accuracy: 0.8525\n",
            "Epoch 70/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8557 - val_loss: 0.4017 - val_accuracy: 0.8566\n",
            "Epoch 71/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8512 - val_loss: 0.3957 - val_accuracy: 0.8620\n",
            "Epoch 72/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8499 - val_loss: 0.3963 - val_accuracy: 0.8634\n",
            "Epoch 73/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8529 - val_loss: 0.4064 - val_accuracy: 0.8566\n",
            "Epoch 74/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8533 - val_loss: 0.4096 - val_accuracy: 0.8552\n",
            "Epoch 75/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8516 - val_loss: 0.4021 - val_accuracy: 0.8593\n",
            "Epoch 76/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8516 - val_loss: 0.4003 - val_accuracy: 0.8538\n",
            "Epoch 77/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8516 - val_loss: 0.4054 - val_accuracy: 0.8538\n",
            "Epoch 78/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8540 - val_loss: 0.3980 - val_accuracy: 0.8648\n",
            "Epoch 79/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8512 - val_loss: 0.3975 - val_accuracy: 0.8620\n",
            "Epoch 80/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8550 - val_loss: 0.4107 - val_accuracy: 0.8525\n",
            "Epoch 81/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8526 - val_loss: 0.3990 - val_accuracy: 0.8579\n",
            "Epoch 82/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8529 - val_loss: 0.3955 - val_accuracy: 0.8607\n",
            "Epoch 83/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8536 - val_loss: 0.4037 - val_accuracy: 0.8552\n",
            "Epoch 84/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8557 - val_loss: 0.4089 - val_accuracy: 0.8538\n",
            "Epoch 85/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8557 - val_loss: 0.4003 - val_accuracy: 0.8579\n",
            "Epoch 86/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8526 - val_loss: 0.3937 - val_accuracy: 0.8634\n",
            "Epoch 87/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8570 - val_loss: 0.4055 - val_accuracy: 0.8566\n",
            "Epoch 88/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8553 - val_loss: 0.4005 - val_accuracy: 0.8566\n",
            "Epoch 89/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8553 - val_loss: 0.3965 - val_accuracy: 0.8593\n",
            "Epoch 90/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8536 - val_loss: 0.4098 - val_accuracy: 0.8511\n",
            "Epoch 91/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8499 - val_loss: 0.4003 - val_accuracy: 0.8620\n",
            "Epoch 92/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8526 - val_loss: 0.4060 - val_accuracy: 0.8607\n",
            "Epoch 93/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8536 - val_loss: 0.4006 - val_accuracy: 0.8607\n",
            "Epoch 94/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8550 - val_loss: 0.4115 - val_accuracy: 0.8566\n",
            "Epoch 95/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8567 - val_loss: 0.4098 - val_accuracy: 0.8593\n",
            "Epoch 96/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8557 - val_loss: 0.4085 - val_accuracy: 0.8484\n",
            "Epoch 97/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8574 - val_loss: 0.4029 - val_accuracy: 0.8579\n",
            "Epoch 98/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8567 - val_loss: 0.3972 - val_accuracy: 0.8607\n",
            "Epoch 99/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8560 - val_loss: 0.4094 - val_accuracy: 0.8484\n",
            "Epoch 100/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8547 - val_loss: 0.4018 - val_accuracy: 0.8552\n",
            "Epoch 101/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8581 - val_loss: 0.3985 - val_accuracy: 0.8579\n",
            "Epoch 102/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8533 - val_loss: 0.3995 - val_accuracy: 0.8607\n",
            "Epoch 103/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8536 - val_loss: 0.3975 - val_accuracy: 0.8607\n",
            "Epoch 104/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8577 - val_loss: 0.4025 - val_accuracy: 0.8579\n",
            "Epoch 105/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8577 - val_loss: 0.4081 - val_accuracy: 0.8566\n",
            "Epoch 106/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8577 - val_loss: 0.4003 - val_accuracy: 0.8579\n",
            "Epoch 107/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8591 - val_loss: 0.4045 - val_accuracy: 0.8566\n",
            "Epoch 108/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8588 - val_loss: 0.3994 - val_accuracy: 0.8566\n",
            "Epoch 109/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8577 - val_loss: 0.4126 - val_accuracy: 0.8538\n",
            "Epoch 110/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8581 - val_loss: 0.3972 - val_accuracy: 0.8579\n",
            "Epoch 111/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8591 - val_loss: 0.4040 - val_accuracy: 0.8538\n",
            "Epoch 112/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8588 - val_loss: 0.4136 - val_accuracy: 0.8566\n",
            "Epoch 113/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8581 - val_loss: 0.4003 - val_accuracy: 0.8634\n",
            "Epoch 114/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8588 - val_loss: 0.4030 - val_accuracy: 0.8620\n",
            "Epoch 115/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8591 - val_loss: 0.4012 - val_accuracy: 0.8593\n",
            "Epoch 116/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8622 - val_loss: 0.3999 - val_accuracy: 0.8579\n",
            "Epoch 117/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8570 - val_loss: 0.3992 - val_accuracy: 0.8566\n",
            "Epoch 118/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8577 - val_loss: 0.4020 - val_accuracy: 0.8607\n",
            "Epoch 119/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8605 - val_loss: 0.4153 - val_accuracy: 0.8470\n",
            "Epoch 120/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8557 - val_loss: 0.4085 - val_accuracy: 0.8579\n",
            "Epoch 121/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8608 - val_loss: 0.4202 - val_accuracy: 0.8443\n",
            "Epoch 122/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8591 - val_loss: 0.4190 - val_accuracy: 0.8470\n",
            "Epoch 123/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8591 - val_loss: 0.4204 - val_accuracy: 0.8538\n",
            "Epoch 124/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8594 - val_loss: 0.3991 - val_accuracy: 0.8607\n",
            "Epoch 125/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8584 - val_loss: 0.4049 - val_accuracy: 0.8579\n",
            "Epoch 126/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8598 - val_loss: 0.4218 - val_accuracy: 0.8538\n",
            "Epoch 127/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8570 - val_loss: 0.4159 - val_accuracy: 0.8538\n",
            "Epoch 128/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8591 - val_loss: 0.3987 - val_accuracy: 0.8620\n",
            "Epoch 129/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8581 - val_loss: 0.4047 - val_accuracy: 0.8511\n",
            "Epoch 130/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8591 - val_loss: 0.4077 - val_accuracy: 0.8607\n",
            "Epoch 131/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8608 - val_loss: 0.4184 - val_accuracy: 0.8497\n",
            "Epoch 132/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8632 - val_loss: 0.4025 - val_accuracy: 0.8607\n",
            "Epoch 133/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8577 - val_loss: 0.4110 - val_accuracy: 0.8566\n",
            "Epoch 134/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8605 - val_loss: 0.4097 - val_accuracy: 0.8593\n",
            "Epoch 135/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8577 - val_loss: 0.3989 - val_accuracy: 0.8579\n",
            "Epoch 136/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8584 - val_loss: 0.4205 - val_accuracy: 0.8470\n",
            "Epoch 137/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8594 - val_loss: 0.4156 - val_accuracy: 0.8593\n",
            "Epoch 138/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8618 - val_loss: 0.4350 - val_accuracy: 0.8361\n",
            "Epoch 139/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8591 - val_loss: 0.4126 - val_accuracy: 0.8566\n",
            "Epoch 140/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8581 - val_loss: 0.4022 - val_accuracy: 0.8579\n",
            "Epoch 141/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8570 - val_loss: 0.4099 - val_accuracy: 0.8607\n",
            "Epoch 142/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8618 - val_loss: 0.4066 - val_accuracy: 0.8648\n",
            "Epoch 143/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8629 - val_loss: 0.4010 - val_accuracy: 0.8593\n",
            "Epoch 144/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8591 - val_loss: 0.4027 - val_accuracy: 0.8579\n",
            "Epoch 145/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8611 - val_loss: 0.4136 - val_accuracy: 0.8593\n",
            "Epoch 146/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8618 - val_loss: 0.4020 - val_accuracy: 0.8593\n",
            "Epoch 147/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8611 - val_loss: 0.4124 - val_accuracy: 0.8607\n",
            "Epoch 148/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8615 - val_loss: 0.4026 - val_accuracy: 0.8579\n",
            "Epoch 149/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8615 - val_loss: 0.4157 - val_accuracy: 0.8579\n",
            "Epoch 150/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8611 - val_loss: 0.4178 - val_accuracy: 0.8579\n",
            "Epoch 151/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8584 - val_loss: 0.4144 - val_accuracy: 0.8538\n",
            "Epoch 152/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8594 - val_loss: 0.4089 - val_accuracy: 0.8525\n",
            "Epoch 153/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8605 - val_loss: 0.4092 - val_accuracy: 0.8620\n",
            "Epoch 154/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8601 - val_loss: 0.4144 - val_accuracy: 0.8579\n",
            "Epoch 155/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8588 - val_loss: 0.4020 - val_accuracy: 0.8607\n",
            "Epoch 156/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8594 - val_loss: 0.4132 - val_accuracy: 0.8552\n",
            "Epoch 157/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8594 - val_loss: 0.4106 - val_accuracy: 0.8552\n",
            "Epoch 158/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8618 - val_loss: 0.4171 - val_accuracy: 0.8620\n",
            "Epoch 159/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8594 - val_loss: 0.4090 - val_accuracy: 0.8566\n",
            "Epoch 160/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8632 - val_loss: 0.4074 - val_accuracy: 0.8552\n",
            "Epoch 161/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8632 - val_loss: 0.4198 - val_accuracy: 0.8538\n",
            "Epoch 162/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8635 - val_loss: 0.4078 - val_accuracy: 0.8593\n",
            "Epoch 163/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8570 - val_loss: 0.4088 - val_accuracy: 0.8607\n",
            "Epoch 164/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8605 - val_loss: 0.4177 - val_accuracy: 0.8484\n",
            "Epoch 165/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8611 - val_loss: 0.4174 - val_accuracy: 0.8579\n",
            "Epoch 166/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8594 - val_loss: 0.4059 - val_accuracy: 0.8620\n",
            "Epoch 167/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8608 - val_loss: 0.4059 - val_accuracy: 0.8552\n",
            "Epoch 168/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8622 - val_loss: 0.4088 - val_accuracy: 0.8593\n",
            "Epoch 169/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8656 - val_loss: 0.4168 - val_accuracy: 0.8484\n",
            "Epoch 170/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8591 - val_loss: 0.4139 - val_accuracy: 0.8634\n",
            "Epoch 171/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8618 - val_loss: 0.4352 - val_accuracy: 0.8470\n",
            "Epoch 172/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8608 - val_loss: 0.4023 - val_accuracy: 0.8607\n",
            "Epoch 173/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8639 - val_loss: 0.4186 - val_accuracy: 0.8566\n",
            "Epoch 174/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8639 - val_loss: 0.4085 - val_accuracy: 0.8552\n",
            "Epoch 175/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8594 - val_loss: 0.4121 - val_accuracy: 0.8661\n",
            "Epoch 176/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8581 - val_loss: 0.4124 - val_accuracy: 0.8634\n",
            "Epoch 177/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8622 - val_loss: 0.4095 - val_accuracy: 0.8579\n",
            "Epoch 178/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8601 - val_loss: 0.4288 - val_accuracy: 0.8566\n",
            "Epoch 179/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8622 - val_loss: 0.4041 - val_accuracy: 0.8566\n",
            "Epoch 180/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8594 - val_loss: 0.4043 - val_accuracy: 0.8579\n",
            "Epoch 181/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8632 - val_loss: 0.4205 - val_accuracy: 0.8538\n",
            "Epoch 182/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8581 - val_loss: 0.4055 - val_accuracy: 0.8648\n",
            "Epoch 183/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8594 - val_loss: 0.4005 - val_accuracy: 0.8593\n",
            "Epoch 184/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8639 - val_loss: 0.4280 - val_accuracy: 0.8566\n",
            "Epoch 185/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8591 - val_loss: 0.4105 - val_accuracy: 0.8593\n",
            "Epoch 186/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8632 - val_loss: 0.4090 - val_accuracy: 0.8607\n",
            "Epoch 187/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8625 - val_loss: 0.3960 - val_accuracy: 0.8648\n",
            "Epoch 188/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8632 - val_loss: 0.4019 - val_accuracy: 0.8634\n",
            "Epoch 189/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8639 - val_loss: 0.4143 - val_accuracy: 0.8511\n",
            "Epoch 190/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8618 - val_loss: 0.4204 - val_accuracy: 0.8511\n",
            "Epoch 191/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8625 - val_loss: 0.4127 - val_accuracy: 0.8525\n",
            "Epoch 192/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8618 - val_loss: 0.4171 - val_accuracy: 0.8511\n",
            "Epoch 193/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8588 - val_loss: 0.3976 - val_accuracy: 0.8634\n",
            "Epoch 194/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8605 - val_loss: 0.4154 - val_accuracy: 0.8497\n",
            "Epoch 195/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8588 - val_loss: 0.4146 - val_accuracy: 0.8579\n",
            "Epoch 196/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8632 - val_loss: 0.4090 - val_accuracy: 0.8511\n",
            "Epoch 197/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8570 - val_loss: 0.4054 - val_accuracy: 0.8620\n",
            "Epoch 198/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8635 - val_loss: 0.4160 - val_accuracy: 0.8552\n",
            "Epoch 199/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8605 - val_loss: 0.4156 - val_accuracy: 0.8566\n",
            "Epoch 200/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8629 - val_loss: 0.4014 - val_accuracy: 0.8634\n",
            "Epoch 201/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8615 - val_loss: 0.4070 - val_accuracy: 0.8607\n",
            "Epoch 202/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8649 - val_loss: 0.4010 - val_accuracy: 0.8648\n",
            "Epoch 203/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8605 - val_loss: 0.4166 - val_accuracy: 0.8552\n",
            "Epoch 204/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8608 - val_loss: 0.4024 - val_accuracy: 0.8593\n",
            "Epoch 205/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8656 - val_loss: 0.3998 - val_accuracy: 0.8620\n",
            "Epoch 206/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8646 - val_loss: 0.4067 - val_accuracy: 0.8607\n",
            "Epoch 207/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8622 - val_loss: 0.4452 - val_accuracy: 0.8470\n",
            "Epoch 208/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8642 - val_loss: 0.4052 - val_accuracy: 0.8648\n",
            "Epoch 209/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8659 - val_loss: 0.4124 - val_accuracy: 0.8634\n",
            "Epoch 210/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8577 - val_loss: 0.4212 - val_accuracy: 0.8538\n",
            "Epoch 211/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8591 - val_loss: 0.4196 - val_accuracy: 0.8552\n",
            "Epoch 212/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8639 - val_loss: 0.4199 - val_accuracy: 0.8538\n",
            "Epoch 213/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8577 - val_loss: 0.3942 - val_accuracy: 0.8634\n",
            "Epoch 214/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8540 - val_loss: 0.4034 - val_accuracy: 0.8620\n",
            "Epoch 215/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8639 - val_loss: 0.4306 - val_accuracy: 0.8511\n",
            "Epoch 216/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8601 - val_loss: 0.4116 - val_accuracy: 0.8607\n",
            "Epoch 217/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8639 - val_loss: 0.4116 - val_accuracy: 0.8538\n",
            "Epoch 218/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8601 - val_loss: 0.4081 - val_accuracy: 0.8525\n",
            "Epoch 219/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8581 - val_loss: 0.4030 - val_accuracy: 0.8634\n",
            "Epoch 220/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8605 - val_loss: 0.4045 - val_accuracy: 0.8607\n",
            "Epoch 221/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8601 - val_loss: 0.4141 - val_accuracy: 0.8525\n",
            "Epoch 222/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8622 - val_loss: 0.3950 - val_accuracy: 0.8675\n",
            "Epoch 223/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8639 - val_loss: 0.4023 - val_accuracy: 0.8607\n",
            "Epoch 224/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8646 - val_loss: 0.4032 - val_accuracy: 0.8579\n",
            "Epoch 225/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8594 - val_loss: 0.4027 - val_accuracy: 0.8552\n",
            "Epoch 226/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8608 - val_loss: 0.4006 - val_accuracy: 0.8620\n",
            "Epoch 227/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8618 - val_loss: 0.4027 - val_accuracy: 0.8607\n",
            "Epoch 228/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8615 - val_loss: 0.4147 - val_accuracy: 0.8607\n",
            "Epoch 229/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8632 - val_loss: 0.4019 - val_accuracy: 0.8675\n",
            "Epoch 230/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8605 - val_loss: 0.4132 - val_accuracy: 0.8552\n",
            "Epoch 231/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8608 - val_loss: 0.4129 - val_accuracy: 0.8620\n",
            "Epoch 232/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8629 - val_loss: 0.4104 - val_accuracy: 0.8566\n",
            "Epoch 233/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8591 - val_loss: 0.4257 - val_accuracy: 0.8415\n",
            "Epoch 234/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8611 - val_loss: 0.4193 - val_accuracy: 0.8593\n",
            "Epoch 235/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8635 - val_loss: 0.4154 - val_accuracy: 0.8538\n",
            "Epoch 236/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8622 - val_loss: 0.4122 - val_accuracy: 0.8579\n",
            "Epoch 237/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8663 - val_loss: 0.4186 - val_accuracy: 0.8552\n",
            "Epoch 238/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8608 - val_loss: 0.4093 - val_accuracy: 0.8620\n",
            "Epoch 239/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8618 - val_loss: 0.4069 - val_accuracy: 0.8634\n",
            "Epoch 240/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8615 - val_loss: 0.4046 - val_accuracy: 0.8566\n",
            "Epoch 241/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8594 - val_loss: 0.4204 - val_accuracy: 0.8566\n",
            "Epoch 242/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8605 - val_loss: 0.4009 - val_accuracy: 0.8634\n",
            "Epoch 243/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8632 - val_loss: 0.4137 - val_accuracy: 0.8443\n",
            "Epoch 244/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8615 - val_loss: 0.4159 - val_accuracy: 0.8579\n",
            "Epoch 245/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8615 - val_loss: 0.4044 - val_accuracy: 0.8593\n",
            "Epoch 246/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8567 - val_loss: 0.4120 - val_accuracy: 0.8470\n",
            "Epoch 247/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8584 - val_loss: 0.3951 - val_accuracy: 0.8634\n",
            "Epoch 248/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8574 - val_loss: 0.4123 - val_accuracy: 0.8579\n",
            "Epoch 249/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8622 - val_loss: 0.4152 - val_accuracy: 0.8470\n",
            "Epoch 250/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8629 - val_loss: 0.4030 - val_accuracy: 0.8648\n",
            "Epoch 251/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8632 - val_loss: 0.4011 - val_accuracy: 0.8620\n",
            "Epoch 252/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8629 - val_loss: 0.4149 - val_accuracy: 0.8402\n",
            "Epoch 253/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8618 - val_loss: 0.4012 - val_accuracy: 0.8634\n",
            "Epoch 254/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8618 - val_loss: 0.4072 - val_accuracy: 0.8634\n",
            "Epoch 255/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8615 - val_loss: 0.4146 - val_accuracy: 0.8579\n",
            "Epoch 256/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8605 - val_loss: 0.4111 - val_accuracy: 0.8525\n",
            "Epoch 257/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8629 - val_loss: 0.4117 - val_accuracy: 0.8497\n",
            "Epoch 258/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8632 - val_loss: 0.4083 - val_accuracy: 0.8607\n",
            "Epoch 259/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8639 - val_loss: 0.3985 - val_accuracy: 0.8620\n",
            "Epoch 260/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8622 - val_loss: 0.4241 - val_accuracy: 0.8497\n",
            "Epoch 261/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8649 - val_loss: 0.4249 - val_accuracy: 0.8525\n",
            "Epoch 262/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8639 - val_loss: 0.4197 - val_accuracy: 0.8579\n",
            "Epoch 263/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8618 - val_loss: 0.4353 - val_accuracy: 0.8388\n",
            "Epoch 264/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8615 - val_loss: 0.4174 - val_accuracy: 0.8525\n",
            "Epoch 265/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8618 - val_loss: 0.3985 - val_accuracy: 0.8634\n",
            "Epoch 266/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8577 - val_loss: 0.4107 - val_accuracy: 0.8648\n",
            "Epoch 267/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8646 - val_loss: 0.4008 - val_accuracy: 0.8607\n",
            "Epoch 268/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8629 - val_loss: 0.4029 - val_accuracy: 0.8579\n",
            "Epoch 269/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8557 - val_loss: 0.4239 - val_accuracy: 0.8525\n",
            "Epoch 270/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8570 - val_loss: 0.4033 - val_accuracy: 0.8634\n",
            "Epoch 271/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8543 - val_loss: 0.4190 - val_accuracy: 0.8579\n",
            "Epoch 272/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8577 - val_loss: 0.4208 - val_accuracy: 0.8429\n",
            "Epoch 273/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8543 - val_loss: 0.4093 - val_accuracy: 0.8620\n",
            "Epoch 274/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8577 - val_loss: 0.4149 - val_accuracy: 0.8607\n",
            "Epoch 275/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8591 - val_loss: 0.4122 - val_accuracy: 0.8620\n",
            "Epoch 276/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8598 - val_loss: 0.4005 - val_accuracy: 0.8620\n",
            "Epoch 277/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8591 - val_loss: 0.4084 - val_accuracy: 0.8552\n",
            "Epoch 278/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8584 - val_loss: 0.4274 - val_accuracy: 0.8470\n",
            "Epoch 279/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8547 - val_loss: 0.4290 - val_accuracy: 0.8456\n",
            "Epoch 280/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8499 - val_loss: 0.4179 - val_accuracy: 0.8566\n",
            "Epoch 281/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8564 - val_loss: 0.4081 - val_accuracy: 0.8620\n",
            "Epoch 282/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8601 - val_loss: 0.4062 - val_accuracy: 0.8607\n",
            "Epoch 283/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8591 - val_loss: 0.4094 - val_accuracy: 0.8566\n",
            "Epoch 284/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8601 - val_loss: 0.4069 - val_accuracy: 0.8552\n",
            "Epoch 285/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8581 - val_loss: 0.4154 - val_accuracy: 0.8538\n",
            "Epoch 286/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8574 - val_loss: 0.4114 - val_accuracy: 0.8620\n",
            "Epoch 287/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8540 - val_loss: 0.4053 - val_accuracy: 0.8634\n",
            "Epoch 288/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8570 - val_loss: 0.3992 - val_accuracy: 0.8661\n",
            "Epoch 289/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8588 - val_loss: 0.4241 - val_accuracy: 0.8525\n",
            "Epoch 290/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8588 - val_loss: 0.4153 - val_accuracy: 0.8566\n",
            "Epoch 291/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8567 - val_loss: 0.4189 - val_accuracy: 0.8579\n",
            "Epoch 292/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8581 - val_loss: 0.4302 - val_accuracy: 0.8648\n",
            "Epoch 293/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8591 - val_loss: 0.4278 - val_accuracy: 0.8566\n",
            "Epoch 294/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8567 - val_loss: 0.4304 - val_accuracy: 0.8593\n",
            "Epoch 295/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8536 - val_loss: 0.4252 - val_accuracy: 0.8497\n",
            "Epoch 296/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8574 - val_loss: 0.4147 - val_accuracy: 0.8552\n",
            "Epoch 297/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8567 - val_loss: 0.4058 - val_accuracy: 0.8648\n",
            "Epoch 298/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8591 - val_loss: 0.4018 - val_accuracy: 0.8648\n",
            "Epoch 299/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8581 - val_loss: 0.4001 - val_accuracy: 0.8634\n",
            "Epoch 300/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8588 - val_loss: 0.4136 - val_accuracy: 0.8538\n",
            "Epoch 301/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8611 - val_loss: 0.4177 - val_accuracy: 0.8579\n",
            "Epoch 302/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8594 - val_loss: 0.4065 - val_accuracy: 0.8607\n",
            "Epoch 303/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8601 - val_loss: 0.4029 - val_accuracy: 0.8661\n",
            "Epoch 304/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8591 - val_loss: 0.4095 - val_accuracy: 0.8634\n",
            "Epoch 305/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8608 - val_loss: 0.4008 - val_accuracy: 0.8661\n",
            "Epoch 306/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8594 - val_loss: 0.4141 - val_accuracy: 0.8511\n",
            "Epoch 307/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8611 - val_loss: 0.4134 - val_accuracy: 0.8648\n",
            "Epoch 308/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8601 - val_loss: 0.4208 - val_accuracy: 0.8689\n",
            "Epoch 309/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8622 - val_loss: 0.4074 - val_accuracy: 0.8607\n",
            "Epoch 310/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8608 - val_loss: 0.4113 - val_accuracy: 0.8634\n",
            "Epoch 311/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8611 - val_loss: 0.4104 - val_accuracy: 0.8648\n",
            "Epoch 312/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8605 - val_loss: 0.4267 - val_accuracy: 0.8648\n",
            "Epoch 313/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8574 - val_loss: 0.4056 - val_accuracy: 0.8648\n",
            "Epoch 314/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8598 - val_loss: 0.4214 - val_accuracy: 0.8579\n",
            "Epoch 315/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8591 - val_loss: 0.4204 - val_accuracy: 0.8538\n",
            "Epoch 316/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8547 - val_loss: 0.4200 - val_accuracy: 0.8511\n",
            "Epoch 317/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8547 - val_loss: 0.4112 - val_accuracy: 0.8620\n",
            "Epoch 318/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8577 - val_loss: 0.4144 - val_accuracy: 0.8593\n",
            "Epoch 319/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8557 - val_loss: 0.4079 - val_accuracy: 0.8579\n",
            "Epoch 320/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8567 - val_loss: 0.4499 - val_accuracy: 0.8402\n",
            "Epoch 321/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8574 - val_loss: 0.4347 - val_accuracy: 0.8470\n",
            "Epoch 322/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8567 - val_loss: 0.4166 - val_accuracy: 0.8620\n",
            "Epoch 323/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8550 - val_loss: 0.4105 - val_accuracy: 0.8634\n",
            "Epoch 324/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8574 - val_loss: 0.4168 - val_accuracy: 0.8566\n",
            "Epoch 325/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8550 - val_loss: 0.4165 - val_accuracy: 0.8552\n",
            "Epoch 326/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8557 - val_loss: 0.4122 - val_accuracy: 0.8566\n",
            "Epoch 327/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8584 - val_loss: 0.4189 - val_accuracy: 0.8566\n",
            "Epoch 328/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8567 - val_loss: 0.4127 - val_accuracy: 0.8634\n",
            "Epoch 329/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8581 - val_loss: 0.4122 - val_accuracy: 0.8648\n",
            "Epoch 330/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8543 - val_loss: 0.4150 - val_accuracy: 0.8538\n",
            "Epoch 331/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8529 - val_loss: 0.4053 - val_accuracy: 0.8593\n",
            "Epoch 332/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8591 - val_loss: 0.4293 - val_accuracy: 0.8497\n",
            "Epoch 333/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8584 - val_loss: 0.4114 - val_accuracy: 0.8566\n",
            "Epoch 334/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8594 - val_loss: 0.4233 - val_accuracy: 0.8552\n",
            "Epoch 335/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8605 - val_loss: 0.4177 - val_accuracy: 0.8579\n",
            "Epoch 336/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8584 - val_loss: 0.4078 - val_accuracy: 0.8552\n",
            "Epoch 337/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8584 - val_loss: 0.4233 - val_accuracy: 0.8552\n",
            "Epoch 338/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8570 - val_loss: 0.4089 - val_accuracy: 0.8579\n",
            "Epoch 339/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8560 - val_loss: 0.4115 - val_accuracy: 0.8593\n",
            "Epoch 340/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8594 - val_loss: 0.4215 - val_accuracy: 0.8552\n",
            "Epoch 341/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8547 - val_loss: 0.4037 - val_accuracy: 0.8566\n",
            "Epoch 342/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8598 - val_loss: 0.4176 - val_accuracy: 0.8634\n",
            "Epoch 343/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8581 - val_loss: 0.4189 - val_accuracy: 0.8566\n",
            "Epoch 344/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8608 - val_loss: 0.4067 - val_accuracy: 0.8593\n",
            "Epoch 345/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8560 - val_loss: 0.4194 - val_accuracy: 0.8566\n",
            "Epoch 346/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8584 - val_loss: 0.4110 - val_accuracy: 0.8648\n",
            "Epoch 347/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8581 - val_loss: 0.4116 - val_accuracy: 0.8525\n",
            "Epoch 348/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8594 - val_loss: 0.4143 - val_accuracy: 0.8525\n",
            "Epoch 349/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8581 - val_loss: 0.3993 - val_accuracy: 0.8675\n",
            "Epoch 350/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8564 - val_loss: 0.4044 - val_accuracy: 0.8620\n",
            "Epoch 351/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8581 - val_loss: 0.4086 - val_accuracy: 0.8552\n",
            "Epoch 352/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8581 - val_loss: 0.3991 - val_accuracy: 0.8634\n",
            "Epoch 353/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8567 - val_loss: 0.4013 - val_accuracy: 0.8620\n",
            "Epoch 354/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8598 - val_loss: 0.4019 - val_accuracy: 0.8661\n",
            "Epoch 355/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8577 - val_loss: 0.4091 - val_accuracy: 0.8552\n",
            "Epoch 356/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8611 - val_loss: 0.4160 - val_accuracy: 0.8511\n",
            "Epoch 357/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8598 - val_loss: 0.4075 - val_accuracy: 0.8579\n",
            "Epoch 358/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8564 - val_loss: 0.3972 - val_accuracy: 0.8607\n",
            "Epoch 359/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8615 - val_loss: 0.4150 - val_accuracy: 0.8593\n",
            "Epoch 360/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8598 - val_loss: 0.4043 - val_accuracy: 0.8661\n",
            "Epoch 361/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8591 - val_loss: 0.4108 - val_accuracy: 0.8648\n",
            "Epoch 362/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8581 - val_loss: 0.4252 - val_accuracy: 0.8484\n",
            "Epoch 363/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8577 - val_loss: 0.4043 - val_accuracy: 0.8648\n",
            "Epoch 364/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8594 - val_loss: 0.4051 - val_accuracy: 0.8607\n",
            "Epoch 365/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8611 - val_loss: 0.4062 - val_accuracy: 0.8593\n",
            "Epoch 366/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8632 - val_loss: 0.4146 - val_accuracy: 0.8484\n",
            "Epoch 367/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8615 - val_loss: 0.4056 - val_accuracy: 0.8511\n",
            "Epoch 368/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8594 - val_loss: 0.3998 - val_accuracy: 0.8607\n",
            "Epoch 369/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8564 - val_loss: 0.4150 - val_accuracy: 0.8497\n",
            "Epoch 370/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8591 - val_loss: 0.4093 - val_accuracy: 0.8552\n",
            "Epoch 371/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8588 - val_loss: 0.4230 - val_accuracy: 0.8511\n",
            "Epoch 372/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8598 - val_loss: 0.4210 - val_accuracy: 0.8607\n",
            "Epoch 373/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8601 - val_loss: 0.4080 - val_accuracy: 0.8607\n",
            "Epoch 374/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8594 - val_loss: 0.4352 - val_accuracy: 0.8443\n",
            "Epoch 375/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8591 - val_loss: 0.4174 - val_accuracy: 0.8593\n",
            "Epoch 376/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8581 - val_loss: 0.4216 - val_accuracy: 0.8566\n",
            "Epoch 377/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8570 - val_loss: 0.4175 - val_accuracy: 0.8497\n",
            "Epoch 378/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8594 - val_loss: 0.4088 - val_accuracy: 0.8552\n",
            "Epoch 379/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8577 - val_loss: 0.4111 - val_accuracy: 0.8579\n",
            "Epoch 380/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8588 - val_loss: 0.4507 - val_accuracy: 0.8511\n",
            "Epoch 381/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8605 - val_loss: 0.4133 - val_accuracy: 0.8566\n",
            "Epoch 382/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8601 - val_loss: 0.4240 - val_accuracy: 0.8538\n",
            "Epoch 383/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8594 - val_loss: 0.4119 - val_accuracy: 0.8607\n",
            "Epoch 384/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8588 - val_loss: 0.4133 - val_accuracy: 0.8607\n",
            "Epoch 385/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8584 - val_loss: 0.4238 - val_accuracy: 0.8593\n",
            "Epoch 386/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8598 - val_loss: 0.4148 - val_accuracy: 0.8538\n",
            "Epoch 387/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8570 - val_loss: 0.4051 - val_accuracy: 0.8620\n",
            "Epoch 388/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8584 - val_loss: 0.4129 - val_accuracy: 0.8620\n",
            "Epoch 389/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8611 - val_loss: 0.4122 - val_accuracy: 0.8620\n",
            "Epoch 390/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8608 - val_loss: 0.4060 - val_accuracy: 0.8648\n",
            "Epoch 391/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8553 - val_loss: 0.3956 - val_accuracy: 0.8620\n",
            "Epoch 392/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8598 - val_loss: 0.4129 - val_accuracy: 0.8607\n",
            "Epoch 393/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8594 - val_loss: 0.4173 - val_accuracy: 0.8484\n",
            "Epoch 394/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8591 - val_loss: 0.4171 - val_accuracy: 0.8579\n",
            "Epoch 395/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8591 - val_loss: 0.4010 - val_accuracy: 0.8648\n",
            "Epoch 396/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8588 - val_loss: 0.4204 - val_accuracy: 0.8538\n",
            "Epoch 397/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8632 - val_loss: 0.4105 - val_accuracy: 0.8620\n",
            "Epoch 398/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8608 - val_loss: 0.4078 - val_accuracy: 0.8552\n",
            "Epoch 399/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8605 - val_loss: 0.4220 - val_accuracy: 0.8538\n",
            "Epoch 400/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8629 - val_loss: 0.4127 - val_accuracy: 0.8593\n",
            "Epoch 401/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8584 - val_loss: 0.4218 - val_accuracy: 0.8552\n",
            "Epoch 402/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8584 - val_loss: 0.4080 - val_accuracy: 0.8607\n",
            "Epoch 403/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8646 - val_loss: 0.4157 - val_accuracy: 0.8593\n",
            "Epoch 404/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8622 - val_loss: 0.3970 - val_accuracy: 0.8675\n",
            "Epoch 405/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8632 - val_loss: 0.4199 - val_accuracy: 0.8593\n",
            "Epoch 406/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8635 - val_loss: 0.4105 - val_accuracy: 0.8648\n",
            "Epoch 407/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8649 - val_loss: 0.4306 - val_accuracy: 0.8484\n",
            "Epoch 408/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8618 - val_loss: 0.4055 - val_accuracy: 0.8620\n",
            "Epoch 409/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8642 - val_loss: 0.4015 - val_accuracy: 0.8607\n",
            "Epoch 410/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8608 - val_loss: 0.4083 - val_accuracy: 0.8620\n",
            "Epoch 411/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8618 - val_loss: 0.4013 - val_accuracy: 0.8634\n",
            "Epoch 412/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8632 - val_loss: 0.4157 - val_accuracy: 0.8607\n",
            "Epoch 413/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8646 - val_loss: 0.4242 - val_accuracy: 0.8456\n",
            "Epoch 414/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8646 - val_loss: 0.4070 - val_accuracy: 0.8648\n",
            "Epoch 415/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8649 - val_loss: 0.4130 - val_accuracy: 0.8579\n",
            "Epoch 416/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8639 - val_loss: 0.4222 - val_accuracy: 0.8566\n",
            "Epoch 417/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8635 - val_loss: 0.4097 - val_accuracy: 0.8634\n",
            "Epoch 418/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8625 - val_loss: 0.4189 - val_accuracy: 0.8525\n",
            "Epoch 419/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8642 - val_loss: 0.4335 - val_accuracy: 0.8484\n",
            "Epoch 420/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8611 - val_loss: 0.4207 - val_accuracy: 0.8552\n",
            "Epoch 421/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8581 - val_loss: 0.4093 - val_accuracy: 0.8538\n",
            "Epoch 422/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8629 - val_loss: 0.4267 - val_accuracy: 0.8593\n",
            "Epoch 423/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8574 - val_loss: 0.4229 - val_accuracy: 0.8497\n",
            "Epoch 424/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8618 - val_loss: 0.4246 - val_accuracy: 0.8634\n",
            "Epoch 425/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8615 - val_loss: 0.4139 - val_accuracy: 0.8675\n",
            "Epoch 426/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8629 - val_loss: 0.4101 - val_accuracy: 0.8552\n",
            "Epoch 427/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8622 - val_loss: 0.4177 - val_accuracy: 0.8593\n",
            "Epoch 428/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8629 - val_loss: 0.4233 - val_accuracy: 0.8511\n",
            "Epoch 429/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8618 - val_loss: 0.4217 - val_accuracy: 0.8470\n",
            "Epoch 430/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8635 - val_loss: 0.4093 - val_accuracy: 0.8607\n",
            "Epoch 431/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8680 - val_loss: 0.4228 - val_accuracy: 0.8607\n",
            "Epoch 432/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8659 - val_loss: 0.4216 - val_accuracy: 0.8607\n",
            "Epoch 433/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8625 - val_loss: 0.4184 - val_accuracy: 0.8620\n",
            "Epoch 434/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8670 - val_loss: 0.4136 - val_accuracy: 0.8634\n",
            "Epoch 435/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8601 - val_loss: 0.4114 - val_accuracy: 0.8607\n",
            "Epoch 436/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8663 - val_loss: 0.4233 - val_accuracy: 0.8538\n",
            "Epoch 437/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8635 - val_loss: 0.4167 - val_accuracy: 0.8497\n",
            "Epoch 438/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8642 - val_loss: 0.4148 - val_accuracy: 0.8579\n",
            "Epoch 439/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8639 - val_loss: 0.4209 - val_accuracy: 0.8566\n",
            "Epoch 440/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8649 - val_loss: 0.4241 - val_accuracy: 0.8525\n",
            "Epoch 441/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8632 - val_loss: 0.4186 - val_accuracy: 0.8552\n",
            "Epoch 442/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8649 - val_loss: 0.4137 - val_accuracy: 0.8579\n",
            "Epoch 443/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8649 - val_loss: 0.4284 - val_accuracy: 0.8538\n",
            "Epoch 444/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8639 - val_loss: 0.4018 - val_accuracy: 0.8607\n",
            "Epoch 445/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8666 - val_loss: 0.4141 - val_accuracy: 0.8648\n",
            "Epoch 446/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8649 - val_loss: 0.4123 - val_accuracy: 0.8607\n",
            "Epoch 447/1000\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8663 - val_loss: 0.4175 - val_accuracy: 0.8525\n",
            "Epoch 448/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8598 - val_loss: 0.4369 - val_accuracy: 0.8456\n",
            "Epoch 449/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8611 - val_loss: 0.4020 - val_accuracy: 0.8607\n",
            "Epoch 450/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8632 - val_loss: 0.4156 - val_accuracy: 0.8566\n",
            "Epoch 451/1000\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8622 - val_loss: 0.4149 - val_accuracy: 0.8607\n",
            "Epoch 452/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8601 - val_loss: 0.4171 - val_accuracy: 0.8593\n",
            "Epoch 453/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8632 - val_loss: 0.4096 - val_accuracy: 0.8579\n",
            "Epoch 454/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8649 - val_loss: 0.4108 - val_accuracy: 0.8538\n",
            "Epoch 455/1000\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8632 - val_loss: 0.4230 - val_accuracy: 0.8470\n",
            "Epoch 456/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8646 - val_loss: 0.4187 - val_accuracy: 0.8593\n",
            "Epoch 457/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8632 - val_loss: 0.4046 - val_accuracy: 0.8579\n",
            "Epoch 458/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8560 - val_loss: 0.4173 - val_accuracy: 0.8525\n",
            "Epoch 459/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8591 - val_loss: 0.4219 - val_accuracy: 0.8525\n",
            "Epoch 460/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8605 - val_loss: 0.4132 - val_accuracy: 0.8566\n",
            "Epoch 461/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8615 - val_loss: 0.4089 - val_accuracy: 0.8511\n",
            "Epoch 462/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8584 - val_loss: 0.4103 - val_accuracy: 0.8525\n",
            "Epoch 463/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8611 - val_loss: 0.4258 - val_accuracy: 0.8443\n",
            "Epoch 464/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8629 - val_loss: 0.4132 - val_accuracy: 0.8552\n",
            "Epoch 465/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8629 - val_loss: 0.4092 - val_accuracy: 0.8593\n",
            "Epoch 466/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8601 - val_loss: 0.4161 - val_accuracy: 0.8525\n",
            "Epoch 467/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8646 - val_loss: 0.4191 - val_accuracy: 0.8593\n",
            "Epoch 468/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8605 - val_loss: 0.4185 - val_accuracy: 0.8538\n",
            "Epoch 469/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8567 - val_loss: 0.4105 - val_accuracy: 0.8538\n",
            "Epoch 470/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8632 - val_loss: 0.4187 - val_accuracy: 0.8538\n",
            "Epoch 471/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8608 - val_loss: 0.4001 - val_accuracy: 0.8607\n",
            "Epoch 472/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8605 - val_loss: 0.4146 - val_accuracy: 0.8538\n",
            "Epoch 473/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8594 - val_loss: 0.4205 - val_accuracy: 0.8593\n",
            "Epoch 474/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8618 - val_loss: 0.4222 - val_accuracy: 0.8620\n",
            "Epoch 475/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8588 - val_loss: 0.4209 - val_accuracy: 0.8525\n",
            "Epoch 476/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8584 - val_loss: 0.4220 - val_accuracy: 0.8538\n",
            "Epoch 477/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8615 - val_loss: 0.4183 - val_accuracy: 0.8552\n",
            "Epoch 478/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8615 - val_loss: 0.4151 - val_accuracy: 0.8538\n",
            "Epoch 479/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8635 - val_loss: 0.4337 - val_accuracy: 0.8497\n",
            "Epoch 480/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8567 - val_loss: 0.4159 - val_accuracy: 0.8620\n",
            "Epoch 481/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8591 - val_loss: 0.4146 - val_accuracy: 0.8607\n",
            "Epoch 482/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8625 - val_loss: 0.4191 - val_accuracy: 0.8497\n",
            "Epoch 483/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8615 - val_loss: 0.4240 - val_accuracy: 0.8593\n",
            "Epoch 484/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8570 - val_loss: 0.4182 - val_accuracy: 0.8566\n",
            "Epoch 485/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8618 - val_loss: 0.4386 - val_accuracy: 0.8456\n",
            "Epoch 486/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8588 - val_loss: 0.4193 - val_accuracy: 0.8607\n",
            "Epoch 487/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8618 - val_loss: 0.4424 - val_accuracy: 0.8388\n",
            "Epoch 488/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8615 - val_loss: 0.4140 - val_accuracy: 0.8579\n",
            "Epoch 489/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8591 - val_loss: 0.3971 - val_accuracy: 0.8593\n",
            "Epoch 490/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8608 - val_loss: 0.4399 - val_accuracy: 0.8347\n",
            "Epoch 491/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8581 - val_loss: 0.4164 - val_accuracy: 0.8634\n",
            "Epoch 492/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8618 - val_loss: 0.4039 - val_accuracy: 0.8620\n",
            "Epoch 493/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8598 - val_loss: 0.4116 - val_accuracy: 0.8593\n",
            "Epoch 494/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8601 - val_loss: 0.4163 - val_accuracy: 0.8538\n",
            "Epoch 495/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8550 - val_loss: 0.4225 - val_accuracy: 0.8538\n",
            "Epoch 496/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8601 - val_loss: 0.4151 - val_accuracy: 0.8470\n",
            "Epoch 497/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8625 - val_loss: 0.4211 - val_accuracy: 0.8538\n",
            "Epoch 498/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8564 - val_loss: 0.4177 - val_accuracy: 0.8538\n",
            "Epoch 499/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8594 - val_loss: 0.4261 - val_accuracy: 0.8511\n",
            "Epoch 500/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8625 - val_loss: 0.4313 - val_accuracy: 0.8429\n",
            "Epoch 501/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8608 - val_loss: 0.4277 - val_accuracy: 0.8470\n",
            "Epoch 502/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8601 - val_loss: 0.4248 - val_accuracy: 0.8443\n",
            "Epoch 503/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8611 - val_loss: 0.4166 - val_accuracy: 0.8552\n",
            "Epoch 504/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8625 - val_loss: 0.4275 - val_accuracy: 0.8402\n",
            "Epoch 505/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8618 - val_loss: 0.4074 - val_accuracy: 0.8525\n",
            "Epoch 506/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8601 - val_loss: 0.4189 - val_accuracy: 0.8484\n",
            "Epoch 507/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8598 - val_loss: 0.4185 - val_accuracy: 0.8497\n",
            "Epoch 508/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8529 - val_loss: 0.4026 - val_accuracy: 0.8538\n",
            "Epoch 509/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8584 - val_loss: 0.4196 - val_accuracy: 0.8538\n",
            "Epoch 510/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8629 - val_loss: 0.4214 - val_accuracy: 0.8593\n",
            "Epoch 511/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8622 - val_loss: 0.4214 - val_accuracy: 0.8566\n",
            "Epoch 512/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8632 - val_loss: 0.4165 - val_accuracy: 0.8607\n",
            "Epoch 513/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8629 - val_loss: 0.4034 - val_accuracy: 0.8566\n",
            "Epoch 514/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8618 - val_loss: 0.4055 - val_accuracy: 0.8566\n",
            "Epoch 515/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8625 - val_loss: 0.4310 - val_accuracy: 0.8525\n",
            "Epoch 516/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8635 - val_loss: 0.4219 - val_accuracy: 0.8511\n",
            "Epoch 517/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8632 - val_loss: 0.4133 - val_accuracy: 0.8484\n",
            "Epoch 518/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8663 - val_loss: 0.4266 - val_accuracy: 0.8497\n",
            "Epoch 519/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8608 - val_loss: 0.4218 - val_accuracy: 0.8497\n",
            "Epoch 520/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8618 - val_loss: 0.4147 - val_accuracy: 0.8607\n",
            "Epoch 521/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8625 - val_loss: 0.4306 - val_accuracy: 0.8497\n",
            "Epoch 522/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8611 - val_loss: 0.4037 - val_accuracy: 0.8593\n",
            "Epoch 523/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8594 - val_loss: 0.4123 - val_accuracy: 0.8497\n",
            "Epoch 524/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8622 - val_loss: 0.4198 - val_accuracy: 0.8566\n",
            "Epoch 525/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8635 - val_loss: 0.4246 - val_accuracy: 0.8497\n",
            "Epoch 526/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8639 - val_loss: 0.4347 - val_accuracy: 0.8443\n",
            "Epoch 527/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8625 - val_loss: 0.4152 - val_accuracy: 0.8497\n",
            "Epoch 528/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8656 - val_loss: 0.4362 - val_accuracy: 0.8429\n",
            "Epoch 529/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8608 - val_loss: 0.4310 - val_accuracy: 0.8484\n",
            "Epoch 530/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8601 - val_loss: 0.4289 - val_accuracy: 0.8484\n",
            "Epoch 531/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8598 - val_loss: 0.4208 - val_accuracy: 0.8566\n",
            "Epoch 532/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8622 - val_loss: 0.4154 - val_accuracy: 0.8538\n",
            "Epoch 533/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8632 - val_loss: 0.4170 - val_accuracy: 0.8497\n",
            "Epoch 534/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8629 - val_loss: 0.4321 - val_accuracy: 0.8388\n",
            "Epoch 535/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8622 - val_loss: 0.4151 - val_accuracy: 0.8566\n",
            "Epoch 536/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8635 - val_loss: 0.4270 - val_accuracy: 0.8538\n",
            "Epoch 537/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8611 - val_loss: 0.4095 - val_accuracy: 0.8566\n",
            "Epoch 538/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8605 - val_loss: 0.4212 - val_accuracy: 0.8525\n",
            "Epoch 539/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8659 - val_loss: 0.4228 - val_accuracy: 0.8525\n",
            "Epoch 540/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8625 - val_loss: 0.4113 - val_accuracy: 0.8538\n",
            "Epoch 541/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8635 - val_loss: 0.4160 - val_accuracy: 0.8552\n",
            "Epoch 542/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8625 - val_loss: 0.4194 - val_accuracy: 0.8552\n",
            "Epoch 543/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8598 - val_loss: 0.4299 - val_accuracy: 0.8443\n",
            "Epoch 544/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8666 - val_loss: 0.4235 - val_accuracy: 0.8511\n",
            "Epoch 545/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8646 - val_loss: 0.4293 - val_accuracy: 0.8484\n",
            "Epoch 546/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8639 - val_loss: 0.4384 - val_accuracy: 0.8470\n",
            "Epoch 547/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8516 - val_loss: 0.3911 - val_accuracy: 0.8648\n",
            "Epoch 548/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8529 - val_loss: 0.4114 - val_accuracy: 0.8525\n",
            "Epoch 549/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8543 - val_loss: 0.4091 - val_accuracy: 0.8593\n",
            "Epoch 550/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8574 - val_loss: 0.4007 - val_accuracy: 0.8620\n",
            "Epoch 551/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8574 - val_loss: 0.4147 - val_accuracy: 0.8525\n",
            "Epoch 552/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8540 - val_loss: 0.4028 - val_accuracy: 0.8579\n",
            "Epoch 553/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8547 - val_loss: 0.4304 - val_accuracy: 0.8538\n",
            "Epoch 554/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8536 - val_loss: 0.4058 - val_accuracy: 0.8620\n",
            "Epoch 555/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8577 - val_loss: 0.4170 - val_accuracy: 0.8648\n",
            "Epoch 556/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8557 - val_loss: 0.4133 - val_accuracy: 0.8593\n",
            "Epoch 557/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8574 - val_loss: 0.4063 - val_accuracy: 0.8607\n",
            "Epoch 558/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8557 - val_loss: 0.4064 - val_accuracy: 0.8634\n",
            "Epoch 559/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8557 - val_loss: 0.4240 - val_accuracy: 0.8566\n",
            "Epoch 560/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8564 - val_loss: 0.4224 - val_accuracy: 0.8620\n",
            "Epoch 561/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8577 - val_loss: 0.3998 - val_accuracy: 0.8648\n",
            "Epoch 562/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8557 - val_loss: 0.3992 - val_accuracy: 0.8607\n",
            "Epoch 563/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8550 - val_loss: 0.4146 - val_accuracy: 0.8579\n",
            "Epoch 564/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8564 - val_loss: 0.4225 - val_accuracy: 0.8566\n",
            "Epoch 565/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8564 - val_loss: 0.4167 - val_accuracy: 0.8566\n",
            "Epoch 566/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8574 - val_loss: 0.4063 - val_accuracy: 0.8620\n",
            "Epoch 567/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8567 - val_loss: 0.3995 - val_accuracy: 0.8634\n",
            "Epoch 568/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8588 - val_loss: 0.4237 - val_accuracy: 0.8470\n",
            "Epoch 569/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8560 - val_loss: 0.3999 - val_accuracy: 0.8607\n",
            "Epoch 570/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8567 - val_loss: 0.4154 - val_accuracy: 0.8566\n",
            "Epoch 571/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8540 - val_loss: 0.4031 - val_accuracy: 0.8607\n",
            "Epoch 572/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8591 - val_loss: 0.4216 - val_accuracy: 0.8620\n",
            "Epoch 573/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8577 - val_loss: 0.4352 - val_accuracy: 0.8607\n",
            "Epoch 574/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8564 - val_loss: 0.4234 - val_accuracy: 0.8566\n",
            "Epoch 575/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8591 - val_loss: 0.4278 - val_accuracy: 0.8552\n",
            "Epoch 576/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8601 - val_loss: 0.4240 - val_accuracy: 0.8566\n",
            "Epoch 577/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8564 - val_loss: 0.4154 - val_accuracy: 0.8607\n",
            "Epoch 578/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8574 - val_loss: 0.4360 - val_accuracy: 0.8538\n",
            "Epoch 579/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8605 - val_loss: 0.4203 - val_accuracy: 0.8566\n",
            "Epoch 580/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8560 - val_loss: 0.4096 - val_accuracy: 0.8634\n",
            "Epoch 581/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8560 - val_loss: 0.4280 - val_accuracy: 0.8620\n",
            "Epoch 582/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8570 - val_loss: 0.4169 - val_accuracy: 0.8620\n",
            "Epoch 583/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8581 - val_loss: 0.4343 - val_accuracy: 0.8552\n",
            "Epoch 584/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8591 - val_loss: 0.4276 - val_accuracy: 0.8579\n",
            "Epoch 585/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8581 - val_loss: 0.4160 - val_accuracy: 0.8634\n",
            "Epoch 586/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8584 - val_loss: 0.4161 - val_accuracy: 0.8593\n",
            "Epoch 587/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8608 - val_loss: 0.4366 - val_accuracy: 0.8579\n",
            "Epoch 588/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8570 - val_loss: 0.4203 - val_accuracy: 0.8607\n",
            "Epoch 589/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8564 - val_loss: 0.4176 - val_accuracy: 0.8620\n",
            "Epoch 590/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8581 - val_loss: 0.4323 - val_accuracy: 0.8579\n",
            "Epoch 591/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8557 - val_loss: 0.4186 - val_accuracy: 0.8620\n",
            "Epoch 592/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8584 - val_loss: 0.4314 - val_accuracy: 0.8607\n",
            "Epoch 593/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8588 - val_loss: 0.4257 - val_accuracy: 0.8620\n",
            "Epoch 594/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8564 - val_loss: 0.4142 - val_accuracy: 0.8593\n",
            "Epoch 595/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8581 - val_loss: 0.4181 - val_accuracy: 0.8579\n",
            "Epoch 596/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8577 - val_loss: 0.4231 - val_accuracy: 0.8607\n",
            "Epoch 597/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8560 - val_loss: 0.4158 - val_accuracy: 0.8607\n",
            "Epoch 598/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8543 - val_loss: 0.4061 - val_accuracy: 0.8607\n",
            "Epoch 599/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8581 - val_loss: 0.4409 - val_accuracy: 0.8566\n",
            "Epoch 600/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8564 - val_loss: 0.4095 - val_accuracy: 0.8648\n",
            "Epoch 601/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8598 - val_loss: 0.4369 - val_accuracy: 0.8566\n",
            "Epoch 602/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8550 - val_loss: 0.4183 - val_accuracy: 0.8607\n",
            "Epoch 603/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8550 - val_loss: 0.4145 - val_accuracy: 0.8566\n",
            "Epoch 604/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8553 - val_loss: 0.4115 - val_accuracy: 0.8538\n",
            "Epoch 605/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8591 - val_loss: 0.4249 - val_accuracy: 0.8593\n",
            "Epoch 606/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8601 - val_loss: 0.4235 - val_accuracy: 0.8566\n",
            "Epoch 607/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8570 - val_loss: 0.4318 - val_accuracy: 0.8593\n",
            "Epoch 608/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8588 - val_loss: 0.4423 - val_accuracy: 0.8511\n",
            "Epoch 609/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8547 - val_loss: 0.4366 - val_accuracy: 0.8607\n",
            "Epoch 610/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8591 - val_loss: 0.4101 - val_accuracy: 0.8607\n",
            "Epoch 611/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8574 - val_loss: 0.4177 - val_accuracy: 0.8661\n",
            "Epoch 612/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8598 - val_loss: 0.4314 - val_accuracy: 0.8579\n",
            "Epoch 613/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8577 - val_loss: 0.4260 - val_accuracy: 0.8511\n",
            "Epoch 614/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8564 - val_loss: 0.4197 - val_accuracy: 0.8620\n",
            "Epoch 615/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8574 - val_loss: 0.4441 - val_accuracy: 0.8566\n",
            "Epoch 616/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8564 - val_loss: 0.4164 - val_accuracy: 0.8607\n",
            "Epoch 617/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8601 - val_loss: 0.4504 - val_accuracy: 0.8525\n",
            "Epoch 618/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8598 - val_loss: 0.4216 - val_accuracy: 0.8607\n",
            "Epoch 619/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8577 - val_loss: 0.4283 - val_accuracy: 0.8566\n",
            "Epoch 620/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8584 - val_loss: 0.4340 - val_accuracy: 0.8579\n",
            "Epoch 621/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8557 - val_loss: 0.4196 - val_accuracy: 0.8566\n",
            "Epoch 622/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8598 - val_loss: 0.4304 - val_accuracy: 0.8566\n",
            "Epoch 623/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8584 - val_loss: 0.4112 - val_accuracy: 0.8593\n",
            "Epoch 624/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8567 - val_loss: 0.4373 - val_accuracy: 0.8566\n",
            "Epoch 625/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8574 - val_loss: 0.4199 - val_accuracy: 0.8620\n",
            "Epoch 626/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8584 - val_loss: 0.4461 - val_accuracy: 0.8456\n",
            "Epoch 627/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8594 - val_loss: 0.4299 - val_accuracy: 0.8552\n",
            "Epoch 628/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8574 - val_loss: 0.4383 - val_accuracy: 0.8579\n",
            "Epoch 629/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8598 - val_loss: 0.4218 - val_accuracy: 0.8579\n",
            "Epoch 630/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8567 - val_loss: 0.4182 - val_accuracy: 0.8607\n",
            "Epoch 631/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8581 - val_loss: 0.4169 - val_accuracy: 0.8579\n",
            "Epoch 632/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8591 - val_loss: 0.4232 - val_accuracy: 0.8620\n",
            "Epoch 633/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8591 - val_loss: 0.4240 - val_accuracy: 0.8607\n",
            "Epoch 634/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8581 - val_loss: 0.4339 - val_accuracy: 0.8607\n",
            "Epoch 635/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8598 - val_loss: 0.4318 - val_accuracy: 0.8593\n",
            "Epoch 636/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8581 - val_loss: 0.4193 - val_accuracy: 0.8579\n",
            "Epoch 637/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8588 - val_loss: 0.4210 - val_accuracy: 0.8538\n",
            "Epoch 638/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8601 - val_loss: 0.4297 - val_accuracy: 0.8607\n",
            "Epoch 639/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8581 - val_loss: 0.4246 - val_accuracy: 0.8620\n",
            "Epoch 640/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8588 - val_loss: 0.4181 - val_accuracy: 0.8593\n",
            "Epoch 641/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8577 - val_loss: 0.4458 - val_accuracy: 0.8538\n",
            "Epoch 642/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8570 - val_loss: 0.4291 - val_accuracy: 0.8634\n",
            "Epoch 643/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8591 - val_loss: 0.4383 - val_accuracy: 0.8648\n",
            "Epoch 644/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8567 - val_loss: 0.4374 - val_accuracy: 0.8607\n",
            "Epoch 645/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8581 - val_loss: 0.4197 - val_accuracy: 0.8593\n",
            "Epoch 646/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8594 - val_loss: 0.4374 - val_accuracy: 0.8607\n",
            "Epoch 647/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8577 - val_loss: 0.4316 - val_accuracy: 0.8538\n",
            "Epoch 648/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8536 - val_loss: 0.4296 - val_accuracy: 0.8579\n",
            "Epoch 649/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8581 - val_loss: 0.4165 - val_accuracy: 0.8620\n",
            "Epoch 650/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8601 - val_loss: 0.4322 - val_accuracy: 0.8579\n",
            "Epoch 651/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8564 - val_loss: 0.4215 - val_accuracy: 0.8634\n",
            "Epoch 652/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8591 - val_loss: 0.4178 - val_accuracy: 0.8607\n",
            "Epoch 653/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8608 - val_loss: 0.4243 - val_accuracy: 0.8634\n",
            "Epoch 654/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8543 - val_loss: 0.4134 - val_accuracy: 0.8620\n",
            "Epoch 655/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8588 - val_loss: 0.4189 - val_accuracy: 0.8552\n",
            "Epoch 656/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8567 - val_loss: 0.4247 - val_accuracy: 0.8538\n",
            "Epoch 657/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8547 - val_loss: 0.4373 - val_accuracy: 0.8620\n",
            "Epoch 658/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8574 - val_loss: 0.4463 - val_accuracy: 0.8538\n",
            "Epoch 659/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8560 - val_loss: 0.4219 - val_accuracy: 0.8552\n",
            "Epoch 660/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8611 - val_loss: 0.4400 - val_accuracy: 0.8566\n",
            "Epoch 661/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8584 - val_loss: 0.4566 - val_accuracy: 0.8443\n",
            "Epoch 662/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8574 - val_loss: 0.4183 - val_accuracy: 0.8620\n",
            "Epoch 663/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8598 - val_loss: 0.4421 - val_accuracy: 0.8525\n",
            "Epoch 664/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8581 - val_loss: 0.4255 - val_accuracy: 0.8620\n",
            "Epoch 665/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8591 - val_loss: 0.4247 - val_accuracy: 0.8525\n",
            "Epoch 666/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8584 - val_loss: 0.4270 - val_accuracy: 0.8566\n",
            "Epoch 667/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8574 - val_loss: 0.4232 - val_accuracy: 0.8620\n",
            "Epoch 668/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8550 - val_loss: 0.4278 - val_accuracy: 0.8538\n",
            "Epoch 669/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8584 - val_loss: 0.4210 - val_accuracy: 0.8579\n",
            "Epoch 670/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8581 - val_loss: 0.4243 - val_accuracy: 0.8538\n",
            "Epoch 671/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8577 - val_loss: 0.4063 - val_accuracy: 0.8593\n",
            "Epoch 672/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8560 - val_loss: 0.4144 - val_accuracy: 0.8648\n",
            "Epoch 673/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8584 - val_loss: 0.4283 - val_accuracy: 0.8552\n",
            "Epoch 674/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8594 - val_loss: 0.4294 - val_accuracy: 0.8620\n",
            "Epoch 675/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8557 - val_loss: 0.4190 - val_accuracy: 0.8607\n",
            "Epoch 676/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8567 - val_loss: 0.4422 - val_accuracy: 0.8456\n",
            "Epoch 677/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8577 - val_loss: 0.4251 - val_accuracy: 0.8593\n",
            "Epoch 678/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8618 - val_loss: 0.4291 - val_accuracy: 0.8593\n",
            "Epoch 679/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8591 - val_loss: 0.4546 - val_accuracy: 0.8552\n",
            "Epoch 680/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8564 - val_loss: 0.4248 - val_accuracy: 0.8552\n",
            "Epoch 681/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8601 - val_loss: 0.4388 - val_accuracy: 0.8579\n",
            "Epoch 682/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8570 - val_loss: 0.4412 - val_accuracy: 0.8607\n",
            "Epoch 683/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8577 - val_loss: 0.4221 - val_accuracy: 0.8620\n",
            "Epoch 684/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8598 - val_loss: 0.4467 - val_accuracy: 0.8538\n",
            "Epoch 685/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8608 - val_loss: 0.4389 - val_accuracy: 0.8593\n",
            "Epoch 686/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8598 - val_loss: 0.4292 - val_accuracy: 0.8634\n",
            "Epoch 687/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8581 - val_loss: 0.4526 - val_accuracy: 0.8566\n",
            "Epoch 688/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8601 - val_loss: 0.4245 - val_accuracy: 0.8620\n",
            "Epoch 689/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8594 - val_loss: 0.4186 - val_accuracy: 0.8593\n",
            "Epoch 690/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8567 - val_loss: 0.4086 - val_accuracy: 0.8634\n",
            "Epoch 691/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8608 - val_loss: 0.4116 - val_accuracy: 0.8566\n",
            "Epoch 692/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8577 - val_loss: 0.4281 - val_accuracy: 0.8552\n",
            "Epoch 693/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8598 - val_loss: 0.4234 - val_accuracy: 0.8566\n",
            "Epoch 694/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8581 - val_loss: 0.4272 - val_accuracy: 0.8607\n",
            "Epoch 695/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8588 - val_loss: 0.4222 - val_accuracy: 0.8593\n",
            "Epoch 696/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8584 - val_loss: 0.4291 - val_accuracy: 0.8593\n",
            "Epoch 697/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8601 - val_loss: 0.4221 - val_accuracy: 0.8593\n",
            "Epoch 698/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8564 - val_loss: 0.4110 - val_accuracy: 0.8607\n",
            "Epoch 699/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8581 - val_loss: 0.4321 - val_accuracy: 0.8566\n",
            "Epoch 700/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8601 - val_loss: 0.4226 - val_accuracy: 0.8607\n",
            "Epoch 701/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8588 - val_loss: 0.4230 - val_accuracy: 0.8620\n",
            "Epoch 702/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8605 - val_loss: 0.4121 - val_accuracy: 0.8607\n",
            "Epoch 703/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8598 - val_loss: 0.4238 - val_accuracy: 0.8620\n",
            "Epoch 704/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8591 - val_loss: 0.4340 - val_accuracy: 0.8620\n",
            "Epoch 705/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8601 - val_loss: 0.4333 - val_accuracy: 0.8579\n",
            "Epoch 706/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8581 - val_loss: 0.4288 - val_accuracy: 0.8566\n",
            "Epoch 707/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8588 - val_loss: 0.4357 - val_accuracy: 0.8579\n",
            "Epoch 708/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8625 - val_loss: 0.4368 - val_accuracy: 0.8593\n",
            "Epoch 709/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8577 - val_loss: 0.4131 - val_accuracy: 0.8593\n",
            "Epoch 710/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8584 - val_loss: 0.4126 - val_accuracy: 0.8593\n",
            "Epoch 711/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8564 - val_loss: 0.4416 - val_accuracy: 0.8566\n",
            "Epoch 712/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8557 - val_loss: 0.4273 - val_accuracy: 0.8620\n",
            "Epoch 713/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8608 - val_loss: 0.4443 - val_accuracy: 0.8538\n",
            "Epoch 714/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8581 - val_loss: 0.4175 - val_accuracy: 0.8579\n",
            "Epoch 715/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8588 - val_loss: 0.4316 - val_accuracy: 0.8593\n",
            "Epoch 716/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8591 - val_loss: 0.4264 - val_accuracy: 0.8511\n",
            "Epoch 717/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8584 - val_loss: 0.4169 - val_accuracy: 0.8648\n",
            "Epoch 718/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8591 - val_loss: 0.4340 - val_accuracy: 0.8525\n",
            "Epoch 719/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8584 - val_loss: 0.4249 - val_accuracy: 0.8552\n",
            "Epoch 720/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8615 - val_loss: 0.4337 - val_accuracy: 0.8566\n",
            "Epoch 721/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8594 - val_loss: 0.4395 - val_accuracy: 0.8566\n",
            "Epoch 722/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8584 - val_loss: 0.4342 - val_accuracy: 0.8593\n",
            "Epoch 723/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8577 - val_loss: 0.4290 - val_accuracy: 0.8634\n",
            "Epoch 724/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8601 - val_loss: 0.4144 - val_accuracy: 0.8579\n",
            "Epoch 725/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8618 - val_loss: 0.4266 - val_accuracy: 0.8552\n",
            "Epoch 726/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8591 - val_loss: 0.4639 - val_accuracy: 0.8538\n",
            "Epoch 727/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8608 - val_loss: 0.4481 - val_accuracy: 0.8415\n",
            "Epoch 728/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8577 - val_loss: 0.4416 - val_accuracy: 0.8552\n",
            "Epoch 729/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8588 - val_loss: 0.4331 - val_accuracy: 0.8538\n",
            "Epoch 730/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8543 - val_loss: 0.4297 - val_accuracy: 0.8579\n",
            "Epoch 731/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8605 - val_loss: 0.4323 - val_accuracy: 0.8607\n",
            "Epoch 732/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8598 - val_loss: 0.4394 - val_accuracy: 0.8552\n",
            "Epoch 733/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8591 - val_loss: 0.4238 - val_accuracy: 0.8648\n",
            "Epoch 734/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8601 - val_loss: 0.4310 - val_accuracy: 0.8552\n",
            "Epoch 735/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8629 - val_loss: 0.4310 - val_accuracy: 0.8566\n",
            "Epoch 736/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8608 - val_loss: 0.4351 - val_accuracy: 0.8579\n",
            "Epoch 737/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8581 - val_loss: 0.4374 - val_accuracy: 0.8552\n",
            "Epoch 738/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8598 - val_loss: 0.4375 - val_accuracy: 0.8538\n",
            "Epoch 739/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8611 - val_loss: 0.4342 - val_accuracy: 0.8497\n",
            "Epoch 740/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8591 - val_loss: 0.4339 - val_accuracy: 0.8607\n",
            "Epoch 741/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8564 - val_loss: 0.4194 - val_accuracy: 0.8593\n",
            "Epoch 742/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8608 - val_loss: 0.4355 - val_accuracy: 0.8607\n",
            "Epoch 743/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8605 - val_loss: 0.4376 - val_accuracy: 0.8620\n",
            "Epoch 744/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8605 - val_loss: 0.4339 - val_accuracy: 0.8525\n",
            "Epoch 745/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8605 - val_loss: 0.4378 - val_accuracy: 0.8607\n",
            "Epoch 746/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8591 - val_loss: 0.4474 - val_accuracy: 0.8607\n",
            "Epoch 747/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8601 - val_loss: 0.4299 - val_accuracy: 0.8607\n",
            "Epoch 748/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8629 - val_loss: 0.4673 - val_accuracy: 0.8593\n",
            "Epoch 749/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8605 - val_loss: 0.4300 - val_accuracy: 0.8566\n",
            "Epoch 750/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8581 - val_loss: 0.4413 - val_accuracy: 0.8579\n",
            "Epoch 751/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8605 - val_loss: 0.4424 - val_accuracy: 0.8456\n",
            "Epoch 752/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8574 - val_loss: 0.4417 - val_accuracy: 0.8470\n",
            "Epoch 753/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8570 - val_loss: 0.4385 - val_accuracy: 0.8525\n",
            "Epoch 754/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8611 - val_loss: 0.4428 - val_accuracy: 0.8538\n",
            "Epoch 755/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8615 - val_loss: 0.4336 - val_accuracy: 0.8620\n",
            "Epoch 756/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8608 - val_loss: 0.4517 - val_accuracy: 0.8538\n",
            "Epoch 757/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8577 - val_loss: 0.4300 - val_accuracy: 0.8579\n",
            "Epoch 758/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8567 - val_loss: 0.4411 - val_accuracy: 0.8593\n",
            "Epoch 759/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8560 - val_loss: 0.4333 - val_accuracy: 0.8620\n",
            "Epoch 760/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8570 - val_loss: 0.4348 - val_accuracy: 0.8566\n",
            "Epoch 761/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8584 - val_loss: 0.4426 - val_accuracy: 0.8579\n",
            "Epoch 762/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8591 - val_loss: 0.4430 - val_accuracy: 0.8579\n",
            "Epoch 763/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8605 - val_loss: 0.4300 - val_accuracy: 0.8484\n",
            "Epoch 764/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8608 - val_loss: 0.4382 - val_accuracy: 0.8634\n",
            "Epoch 765/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8577 - val_loss: 0.4408 - val_accuracy: 0.8566\n",
            "Epoch 766/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8598 - val_loss: 0.4461 - val_accuracy: 0.8566\n",
            "Epoch 767/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8611 - val_loss: 0.4482 - val_accuracy: 0.8593\n",
            "Epoch 768/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8570 - val_loss: 0.4424 - val_accuracy: 0.8607\n",
            "Epoch 769/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8605 - val_loss: 0.4439 - val_accuracy: 0.8593\n",
            "Epoch 770/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8611 - val_loss: 0.4432 - val_accuracy: 0.8484\n",
            "Epoch 771/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8622 - val_loss: 0.4465 - val_accuracy: 0.8552\n",
            "Epoch 772/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8584 - val_loss: 0.4377 - val_accuracy: 0.8648\n",
            "Epoch 773/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8577 - val_loss: 0.4428 - val_accuracy: 0.8525\n",
            "Epoch 774/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8611 - val_loss: 0.4426 - val_accuracy: 0.8538\n",
            "Epoch 775/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8629 - val_loss: 0.4521 - val_accuracy: 0.8470\n",
            "Epoch 776/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8605 - val_loss: 0.4508 - val_accuracy: 0.8607\n",
            "Epoch 777/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8605 - val_loss: 0.4712 - val_accuracy: 0.8552\n",
            "Epoch 778/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8601 - val_loss: 0.4359 - val_accuracy: 0.8497\n",
            "Epoch 779/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8622 - val_loss: 0.4282 - val_accuracy: 0.8566\n",
            "Epoch 780/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8605 - val_loss: 0.4276 - val_accuracy: 0.8525\n",
            "Epoch 781/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8591 - val_loss: 0.4253 - val_accuracy: 0.8620\n",
            "Epoch 782/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8594 - val_loss: 0.4657 - val_accuracy: 0.8538\n",
            "Epoch 783/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8608 - val_loss: 0.4517 - val_accuracy: 0.8511\n",
            "Epoch 784/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8601 - val_loss: 0.4381 - val_accuracy: 0.8579\n",
            "Epoch 785/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8588 - val_loss: 0.4453 - val_accuracy: 0.8566\n",
            "Epoch 786/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8577 - val_loss: 0.4451 - val_accuracy: 0.8552\n",
            "Epoch 787/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8629 - val_loss: 0.4508 - val_accuracy: 0.8511\n",
            "Epoch 788/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8608 - val_loss: 0.4362 - val_accuracy: 0.8552\n",
            "Epoch 789/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8611 - val_loss: 0.4431 - val_accuracy: 0.8497\n",
            "Epoch 790/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8618 - val_loss: 0.4506 - val_accuracy: 0.8511\n",
            "Epoch 791/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8625 - val_loss: 0.4395 - val_accuracy: 0.8552\n",
            "Epoch 792/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8588 - val_loss: 0.4386 - val_accuracy: 0.8552\n",
            "Epoch 793/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8608 - val_loss: 0.4516 - val_accuracy: 0.8511\n",
            "Epoch 794/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8635 - val_loss: 0.4521 - val_accuracy: 0.8552\n",
            "Epoch 795/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8601 - val_loss: 0.4446 - val_accuracy: 0.8552\n",
            "Epoch 796/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8594 - val_loss: 0.4555 - val_accuracy: 0.8525\n",
            "Epoch 797/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8605 - val_loss: 0.4328 - val_accuracy: 0.8607\n",
            "Epoch 798/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8625 - val_loss: 0.4345 - val_accuracy: 0.8579\n",
            "Epoch 799/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8581 - val_loss: 0.4582 - val_accuracy: 0.8552\n",
            "Epoch 800/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8615 - val_loss: 0.4360 - val_accuracy: 0.8484\n",
            "Epoch 801/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8591 - val_loss: 0.4263 - val_accuracy: 0.8593\n",
            "Epoch 802/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8584 - val_loss: 0.4192 - val_accuracy: 0.8593\n",
            "Epoch 803/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8574 - val_loss: 0.4140 - val_accuracy: 0.8634\n",
            "Epoch 804/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8588 - val_loss: 0.4296 - val_accuracy: 0.8456\n",
            "Epoch 805/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8557 - val_loss: 0.4151 - val_accuracy: 0.8593\n",
            "Epoch 806/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8591 - val_loss: 0.4326 - val_accuracy: 0.8566\n",
            "Epoch 807/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8584 - val_loss: 0.4338 - val_accuracy: 0.8607\n",
            "Epoch 808/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8598 - val_loss: 0.4204 - val_accuracy: 0.8634\n",
            "Epoch 809/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8615 - val_loss: 0.4324 - val_accuracy: 0.8607\n",
            "Epoch 810/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8594 - val_loss: 0.4313 - val_accuracy: 0.8593\n",
            "Epoch 811/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8618 - val_loss: 0.4304 - val_accuracy: 0.8593\n",
            "Epoch 812/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8588 - val_loss: 0.4300 - val_accuracy: 0.8579\n",
            "Epoch 813/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8608 - val_loss: 0.4430 - val_accuracy: 0.8620\n",
            "Epoch 814/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8598 - val_loss: 0.4310 - val_accuracy: 0.8593\n",
            "Epoch 815/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8591 - val_loss: 0.4254 - val_accuracy: 0.8566\n",
            "Epoch 816/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8608 - val_loss: 0.4479 - val_accuracy: 0.8538\n",
            "Epoch 817/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8605 - val_loss: 0.4466 - val_accuracy: 0.8511\n",
            "Epoch 818/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8550 - val_loss: 0.4410 - val_accuracy: 0.8634\n",
            "Epoch 819/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8557 - val_loss: 0.4140 - val_accuracy: 0.8566\n",
            "Epoch 820/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8605 - val_loss: 0.4416 - val_accuracy: 0.8538\n",
            "Epoch 821/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8584 - val_loss: 0.4333 - val_accuracy: 0.8607\n",
            "Epoch 822/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8605 - val_loss: 0.4585 - val_accuracy: 0.8497\n",
            "Epoch 823/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8594 - val_loss: 0.4654 - val_accuracy: 0.8552\n",
            "Epoch 824/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8605 - val_loss: 0.4473 - val_accuracy: 0.8566\n",
            "Epoch 825/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8611 - val_loss: 0.4245 - val_accuracy: 0.8620\n",
            "Epoch 826/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8605 - val_loss: 0.4428 - val_accuracy: 0.8579\n",
            "Epoch 827/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8611 - val_loss: 0.4617 - val_accuracy: 0.8511\n",
            "Epoch 828/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8588 - val_loss: 0.4446 - val_accuracy: 0.8566\n",
            "Epoch 829/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8605 - val_loss: 0.4412 - val_accuracy: 0.8538\n",
            "Epoch 830/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8618 - val_loss: 0.4693 - val_accuracy: 0.8552\n",
            "Epoch 831/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8605 - val_loss: 0.4417 - val_accuracy: 0.8634\n",
            "Epoch 832/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8611 - val_loss: 0.4296 - val_accuracy: 0.8566\n",
            "Epoch 833/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8574 - val_loss: 0.4615 - val_accuracy: 0.8511\n",
            "Epoch 834/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8605 - val_loss: 0.4495 - val_accuracy: 0.8511\n",
            "Epoch 835/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8581 - val_loss: 0.4303 - val_accuracy: 0.8566\n",
            "Epoch 836/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8605 - val_loss: 0.4453 - val_accuracy: 0.8607\n",
            "Epoch 837/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8611 - val_loss: 0.4345 - val_accuracy: 0.8566\n",
            "Epoch 838/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8611 - val_loss: 0.4570 - val_accuracy: 0.8497\n",
            "Epoch 839/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8581 - val_loss: 0.4415 - val_accuracy: 0.8607\n",
            "Epoch 840/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8629 - val_loss: 0.4186 - val_accuracy: 0.8634\n",
            "Epoch 841/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8570 - val_loss: 0.4383 - val_accuracy: 0.8538\n",
            "Epoch 842/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8618 - val_loss: 0.4492 - val_accuracy: 0.8566\n",
            "Epoch 843/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8608 - val_loss: 0.4477 - val_accuracy: 0.8525\n",
            "Epoch 844/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8588 - val_loss: 0.4335 - val_accuracy: 0.8607\n",
            "Epoch 845/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8611 - val_loss: 0.4277 - val_accuracy: 0.8566\n",
            "Epoch 846/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8605 - val_loss: 0.4480 - val_accuracy: 0.8566\n",
            "Epoch 847/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8635 - val_loss: 0.4369 - val_accuracy: 0.8525\n",
            "Epoch 848/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8560 - val_loss: 0.4384 - val_accuracy: 0.8525\n",
            "Epoch 849/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8601 - val_loss: 0.4459 - val_accuracy: 0.8456\n",
            "Epoch 850/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8574 - val_loss: 0.4335 - val_accuracy: 0.8634\n",
            "Epoch 851/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8574 - val_loss: 0.4355 - val_accuracy: 0.8579\n",
            "Epoch 852/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8598 - val_loss: 0.4375 - val_accuracy: 0.8497\n",
            "Epoch 853/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8611 - val_loss: 0.4384 - val_accuracy: 0.8593\n",
            "Epoch 854/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8615 - val_loss: 0.4444 - val_accuracy: 0.8579\n",
            "Epoch 855/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8632 - val_loss: 0.4368 - val_accuracy: 0.8525\n",
            "Epoch 856/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8601 - val_loss: 0.4390 - val_accuracy: 0.8538\n",
            "Epoch 857/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8618 - val_loss: 0.4629 - val_accuracy: 0.8497\n",
            "Epoch 858/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8588 - val_loss: 0.4312 - val_accuracy: 0.8552\n",
            "Epoch 859/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8629 - val_loss: 0.4430 - val_accuracy: 0.8552\n",
            "Epoch 860/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8560 - val_loss: 0.4292 - val_accuracy: 0.8552\n",
            "Epoch 861/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8584 - val_loss: 0.4321 - val_accuracy: 0.8620\n",
            "Epoch 862/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8553 - val_loss: 0.4237 - val_accuracy: 0.8566\n",
            "Epoch 863/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8601 - val_loss: 0.4388 - val_accuracy: 0.8525\n",
            "Epoch 864/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8574 - val_loss: 0.4319 - val_accuracy: 0.8566\n",
            "Epoch 865/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8605 - val_loss: 0.4482 - val_accuracy: 0.8607\n",
            "Epoch 866/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8611 - val_loss: 0.4470 - val_accuracy: 0.8497\n",
            "Epoch 867/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8618 - val_loss: 0.4431 - val_accuracy: 0.8593\n",
            "Epoch 868/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8622 - val_loss: 0.4274 - val_accuracy: 0.8552\n",
            "Epoch 869/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8581 - val_loss: 0.4450 - val_accuracy: 0.8579\n",
            "Epoch 870/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8611 - val_loss: 0.4691 - val_accuracy: 0.8552\n",
            "Epoch 871/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8574 - val_loss: 0.4522 - val_accuracy: 0.8566\n",
            "Epoch 872/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8639 - val_loss: 0.4367 - val_accuracy: 0.8552\n",
            "Epoch 873/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8605 - val_loss: 0.4242 - val_accuracy: 0.8607\n",
            "Epoch 874/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8618 - val_loss: 0.4524 - val_accuracy: 0.8538\n",
            "Epoch 875/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8608 - val_loss: 0.4339 - val_accuracy: 0.8579\n",
            "Epoch 876/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8615 - val_loss: 0.4566 - val_accuracy: 0.8552\n",
            "Epoch 877/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8601 - val_loss: 0.4527 - val_accuracy: 0.8566\n",
            "Epoch 878/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8629 - val_loss: 0.4310 - val_accuracy: 0.8579\n",
            "Epoch 879/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8591 - val_loss: 0.4610 - val_accuracy: 0.8579\n",
            "Epoch 880/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8629 - val_loss: 0.4423 - val_accuracy: 0.8552\n",
            "Epoch 881/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8639 - val_loss: 0.4500 - val_accuracy: 0.8538\n",
            "Epoch 882/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8611 - val_loss: 0.4388 - val_accuracy: 0.8593\n",
            "Epoch 883/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8629 - val_loss: 0.4341 - val_accuracy: 0.8579\n",
            "Epoch 884/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8618 - val_loss: 0.4437 - val_accuracy: 0.8470\n",
            "Epoch 885/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8611 - val_loss: 0.4492 - val_accuracy: 0.8511\n",
            "Epoch 886/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8577 - val_loss: 0.4467 - val_accuracy: 0.8525\n",
            "Epoch 887/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8625 - val_loss: 0.4520 - val_accuracy: 0.8525\n",
            "Epoch 888/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8615 - val_loss: 0.4391 - val_accuracy: 0.8579\n",
            "Epoch 889/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8642 - val_loss: 0.4666 - val_accuracy: 0.8566\n",
            "Epoch 890/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8591 - val_loss: 0.4429 - val_accuracy: 0.8607\n",
            "Epoch 891/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8625 - val_loss: 0.4575 - val_accuracy: 0.8566\n",
            "Epoch 892/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8618 - val_loss: 0.4583 - val_accuracy: 0.8552\n",
            "Epoch 893/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8605 - val_loss: 0.4531 - val_accuracy: 0.8538\n",
            "Epoch 894/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8598 - val_loss: 0.4716 - val_accuracy: 0.8566\n",
            "Epoch 895/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8611 - val_loss: 0.4373 - val_accuracy: 0.8620\n",
            "Epoch 896/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8591 - val_loss: 0.4570 - val_accuracy: 0.8566\n",
            "Epoch 897/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8594 - val_loss: 0.4548 - val_accuracy: 0.8552\n",
            "Epoch 898/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8591 - val_loss: 0.4226 - val_accuracy: 0.8620\n",
            "Epoch 899/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8594 - val_loss: 0.4454 - val_accuracy: 0.8593\n",
            "Epoch 900/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8615 - val_loss: 0.4621 - val_accuracy: 0.8579\n",
            "Epoch 901/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8611 - val_loss: 0.4427 - val_accuracy: 0.8525\n",
            "Epoch 902/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8605 - val_loss: 0.4594 - val_accuracy: 0.8566\n",
            "Epoch 903/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8584 - val_loss: 0.4340 - val_accuracy: 0.8511\n",
            "Epoch 904/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8584 - val_loss: 0.4387 - val_accuracy: 0.8538\n",
            "Epoch 905/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8611 - val_loss: 0.4372 - val_accuracy: 0.8525\n",
            "Epoch 906/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8611 - val_loss: 0.4488 - val_accuracy: 0.8511\n",
            "Epoch 907/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8570 - val_loss: 0.4399 - val_accuracy: 0.8620\n",
            "Epoch 908/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8639 - val_loss: 0.4624 - val_accuracy: 0.8552\n",
            "Epoch 909/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8625 - val_loss: 0.4332 - val_accuracy: 0.8579\n",
            "Epoch 910/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8625 - val_loss: 0.4695 - val_accuracy: 0.8538\n",
            "Epoch 911/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8615 - val_loss: 0.4369 - val_accuracy: 0.8497\n",
            "Epoch 912/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8581 - val_loss: 0.4242 - val_accuracy: 0.8593\n",
            "Epoch 913/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8598 - val_loss: 0.4485 - val_accuracy: 0.8552\n",
            "Epoch 914/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8581 - val_loss: 0.4522 - val_accuracy: 0.8579\n",
            "Epoch 915/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8611 - val_loss: 0.4349 - val_accuracy: 0.8552\n",
            "Epoch 916/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8608 - val_loss: 0.4367 - val_accuracy: 0.8525\n",
            "Epoch 917/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8639 - val_loss: 0.4561 - val_accuracy: 0.8538\n",
            "Epoch 918/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8625 - val_loss: 0.4551 - val_accuracy: 0.8566\n",
            "Epoch 919/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8588 - val_loss: 0.4427 - val_accuracy: 0.8552\n",
            "Epoch 920/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8632 - val_loss: 0.4493 - val_accuracy: 0.8525\n",
            "Epoch 921/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8605 - val_loss: 0.4529 - val_accuracy: 0.8648\n",
            "Epoch 922/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8601 - val_loss: 0.4555 - val_accuracy: 0.8538\n",
            "Epoch 923/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8632 - val_loss: 0.4497 - val_accuracy: 0.8566\n",
            "Epoch 924/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8649 - val_loss: 0.4543 - val_accuracy: 0.8593\n",
            "Epoch 925/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8625 - val_loss: 0.4395 - val_accuracy: 0.8579\n",
            "Epoch 926/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8615 - val_loss: 0.4578 - val_accuracy: 0.8566\n",
            "Epoch 927/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8564 - val_loss: 0.4489 - val_accuracy: 0.8552\n",
            "Epoch 928/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8622 - val_loss: 0.4464 - val_accuracy: 0.8620\n",
            "Epoch 929/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8622 - val_loss: 0.4386 - val_accuracy: 0.8552\n",
            "Epoch 930/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8605 - val_loss: 0.4364 - val_accuracy: 0.8620\n",
            "Epoch 931/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8594 - val_loss: 0.4417 - val_accuracy: 0.8511\n",
            "Epoch 932/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8608 - val_loss: 0.4590 - val_accuracy: 0.8511\n",
            "Epoch 933/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8611 - val_loss: 0.4548 - val_accuracy: 0.8484\n",
            "Epoch 934/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8605 - val_loss: 0.4411 - val_accuracy: 0.8552\n",
            "Epoch 935/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8618 - val_loss: 0.4345 - val_accuracy: 0.8538\n",
            "Epoch 936/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8632 - val_loss: 0.4365 - val_accuracy: 0.8566\n",
            "Epoch 937/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8605 - val_loss: 0.4342 - val_accuracy: 0.8552\n",
            "Epoch 938/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8618 - val_loss: 0.4363 - val_accuracy: 0.8566\n",
            "Epoch 939/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8581 - val_loss: 0.4311 - val_accuracy: 0.8593\n",
            "Epoch 940/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8584 - val_loss: 0.4305 - val_accuracy: 0.8648\n",
            "Epoch 941/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8577 - val_loss: 0.4391 - val_accuracy: 0.8484\n",
            "Epoch 942/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8605 - val_loss: 0.4538 - val_accuracy: 0.8470\n",
            "Epoch 943/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8560 - val_loss: 0.4613 - val_accuracy: 0.8538\n",
            "Epoch 944/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8598 - val_loss: 0.4375 - val_accuracy: 0.8538\n",
            "Epoch 945/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8625 - val_loss: 0.4520 - val_accuracy: 0.8552\n",
            "Epoch 946/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8588 - val_loss: 0.4144 - val_accuracy: 0.8620\n",
            "Epoch 947/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8611 - val_loss: 0.4337 - val_accuracy: 0.8593\n",
            "Epoch 948/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8622 - val_loss: 0.4384 - val_accuracy: 0.8538\n",
            "Epoch 949/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8632 - val_loss: 0.4530 - val_accuracy: 0.8579\n",
            "Epoch 950/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8601 - val_loss: 0.4568 - val_accuracy: 0.8525\n",
            "Epoch 951/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8622 - val_loss: 0.4619 - val_accuracy: 0.8470\n",
            "Epoch 952/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8601 - val_loss: 0.4544 - val_accuracy: 0.8579\n",
            "Epoch 953/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8625 - val_loss: 0.4615 - val_accuracy: 0.8497\n",
            "Epoch 954/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8632 - val_loss: 0.4684 - val_accuracy: 0.8566\n",
            "Epoch 955/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8625 - val_loss: 0.4504 - val_accuracy: 0.8511\n",
            "Epoch 956/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8618 - val_loss: 0.4543 - val_accuracy: 0.8538\n",
            "Epoch 957/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8615 - val_loss: 0.4517 - val_accuracy: 0.8566\n",
            "Epoch 958/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8611 - val_loss: 0.4562 - val_accuracy: 0.8620\n",
            "Epoch 959/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8608 - val_loss: 0.4706 - val_accuracy: 0.8552\n",
            "Epoch 960/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8608 - val_loss: 0.4669 - val_accuracy: 0.8620\n",
            "Epoch 961/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8632 - val_loss: 0.4650 - val_accuracy: 0.8538\n",
            "Epoch 962/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8618 - val_loss: 0.4451 - val_accuracy: 0.8648\n",
            "Epoch 963/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8615 - val_loss: 0.4597 - val_accuracy: 0.8525\n",
            "Epoch 964/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8625 - val_loss: 0.4587 - val_accuracy: 0.8538\n",
            "Epoch 965/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8629 - val_loss: 0.4554 - val_accuracy: 0.8525\n",
            "Epoch 966/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8615 - val_loss: 0.4782 - val_accuracy: 0.8456\n",
            "Epoch 967/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8639 - val_loss: 0.4501 - val_accuracy: 0.8620\n",
            "Epoch 968/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8608 - val_loss: 0.4376 - val_accuracy: 0.8620\n",
            "Epoch 969/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8570 - val_loss: 0.4412 - val_accuracy: 0.8593\n",
            "Epoch 970/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8632 - val_loss: 0.4456 - val_accuracy: 0.8552\n",
            "Epoch 971/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8615 - val_loss: 0.4427 - val_accuracy: 0.8484\n",
            "Epoch 972/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8622 - val_loss: 0.4551 - val_accuracy: 0.8538\n",
            "Epoch 973/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8635 - val_loss: 0.4461 - val_accuracy: 0.8525\n",
            "Epoch 974/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8581 - val_loss: 0.4447 - val_accuracy: 0.8552\n",
            "Epoch 975/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8588 - val_loss: 0.4510 - val_accuracy: 0.8511\n",
            "Epoch 976/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8618 - val_loss: 0.4553 - val_accuracy: 0.8497\n",
            "Epoch 977/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8618 - val_loss: 0.4698 - val_accuracy: 0.8538\n",
            "Epoch 978/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8625 - val_loss: 0.4605 - val_accuracy: 0.8497\n",
            "Epoch 979/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8608 - val_loss: 0.4454 - val_accuracy: 0.8579\n",
            "Epoch 980/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8608 - val_loss: 0.4476 - val_accuracy: 0.8538\n",
            "Epoch 981/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8601 - val_loss: 0.4512 - val_accuracy: 0.8511\n",
            "Epoch 982/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8629 - val_loss: 0.4515 - val_accuracy: 0.8552\n",
            "Epoch 983/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8618 - val_loss: 0.4647 - val_accuracy: 0.8593\n",
            "Epoch 984/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8577 - val_loss: 0.4420 - val_accuracy: 0.8593\n",
            "Epoch 985/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8581 - val_loss: 0.4377 - val_accuracy: 0.8607\n",
            "Epoch 986/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8601 - val_loss: 0.4794 - val_accuracy: 0.8538\n",
            "Epoch 987/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8632 - val_loss: 0.4600 - val_accuracy: 0.8648\n",
            "Epoch 988/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8611 - val_loss: 0.4281 - val_accuracy: 0.8620\n",
            "Epoch 989/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8632 - val_loss: 0.4506 - val_accuracy: 0.8552\n",
            "Epoch 990/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8601 - val_loss: 0.4283 - val_accuracy: 0.8566\n",
            "Epoch 991/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8577 - val_loss: 0.4278 - val_accuracy: 0.8593\n",
            "Epoch 992/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8618 - val_loss: 0.4469 - val_accuracy: 0.8538\n",
            "Epoch 993/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8622 - val_loss: 0.4530 - val_accuracy: 0.8511\n",
            "Epoch 994/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8591 - val_loss: 0.4499 - val_accuracy: 0.8620\n",
            "Epoch 995/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8611 - val_loss: 0.4667 - val_accuracy: 0.8579\n",
            "Epoch 996/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8591 - val_loss: 0.4568 - val_accuracy: 0.8566\n",
            "Epoch 997/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8622 - val_loss: 0.4626 - val_accuracy: 0.8511\n",
            "Epoch 998/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8584 - val_loss: 0.4550 - val_accuracy: 0.8552\n",
            "Epoch 999/1000\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8605 - val_loss: 0.4448 - val_accuracy: 0.8552\n",
            "Epoch 1000/1000\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8608 - val_loss: 0.4613 - val_accuracy: 0.8552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDw09InASr5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e5922dca-7129-403b-db7a-ad5a9d8a17f7"
      },
      "source": [
        "print(model.evaluate(X_test,Y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8552\n",
            "[0.4613020718097687, 0.8551912307739258]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHZEYkoeE0Np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36c6c868-6489-4fd6-ccbe-12c2618e0b90"
      },
      "source": [
        "y_pred=model.predict_classes([[ 0,\t61,\t3.0,\t1,\t30.0\t,1.0,\t1,\t0,\t1,\t100.0,\t150.0,\t95.0\t,20.58,\t65.0,\t103.0\t]])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLNEstny5S-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d6fab89-c124-4b72-93c7-83d5ce3d93f8"
      },
      "source": [
        "y_pred1=model.predict([[ 0,\t61,\t3.0,\t1,\t30.0\t,1.0,\t1,\t0,\t1,\t100.0,\t150.0,\t95.0\t,20.58,\t65.0,\t103.0\t]])\n",
        "y_pred1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.626552  , 0.37415588]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXDMgzzLU4aN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8eb844f5-e9c0-4ae8-ab32-ab19383eac02"
      },
      "source": [
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Validation Loss','Training Loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmHkOtl7YZty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ab453ed3-311c-4d47-e0c3-1f21f6fa06f2"
      },
      "source": [
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Validation Data','Train Data'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW2_XZ32onXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}